This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-01-03T08:46:45.077Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

- Line numbers have been added to the beginning of each line.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
agents/
  agents.py
  file_writer_agent.py
  zapper.py
cli/
  child_terminal.py
  cli.py
  listener.py
  process_monitor.py
handlers/
  fastapi_handlers.py
process/
  agent_handler.py
  process.py
repomixer/
  context_collector.py
  stack_trace_parser.py
shelly.egg-info/
  dependency_links.txt
  entry_points.txt
  PKG-INFO
  requires.txt
  SOURCES.txt
  top_level.txt
terminalout/
  terminal.py
test/
  test-nextjs-project/
    src/
      app/
        globals.css
        layout.tsx
        page.tsx
    .eslintrc.json
    .gitignore
    next.config.mjs
    package.json
    postcss.config.mjs
    README.md
    tailwind.config.ts
    tsconfig.json
  test-react-app/
    public/
      index.html
      manifest.json
      robots.txt
    src/
      App.css
      App.js
      App.test.js
      index.css
      index.js
      logo.svg
      reportWebVitals.js
      setupTests.js
    .gitignore
    package.json
    README.md
  FaultyJava.java
  main.py
  test.c
  test.js
  test.py
  test.ts
utils/
  utils.py
.env.example
.gitignore
config.toml
errortrace.py
humanloop.ipynb
module.py
README.md
relational.py
requirements.txt
setup.py
setup.sh
test.py

================================================================
Repository Files
================================================================

================
File: agents/agents.py
================
 1: from json import tool
 2: from dataclasses import dataclass
 3: from pydantic import BaseModel, Field
 4: from pydantic_ai import Agent, RunContext
 5: from dotenv import load_dotenv
 6: import os
 7: from pathlib import Path
 8: from typing import Union, Optional
 9: 
10: load_dotenv()
11: 
12: @dataclass
13: class FlagDependencies:
14:     flag: str
15:     file_path: Union[str,Path]
16: 
17:     def __post_init__(self):
18:         try:
19:             self.file_path = Path(self.file_path)
20:             if not self.file_path.exists():
21:                 cwd = os.getcwd()
22: 
23:         except OSError as e:
24: 
25: 
26: 
27: 
28: class ZapperResult(BaseModel):
29:     path: str = Field("The path to the file where the error occurs")
30:     file: str = Field("The name of the file with the error")
31:     line: int = Field("Which line the error occured in", ge=0)
32:     what: str = Field("Explanation in natural language of what the error is")
33:     todo: str = Field("Describe steps to take in natural language in order to fix the error")
34: 
35: 
36: bug_zapper = Agent(
37:     model_name=os.getenv('MODEL'),
38:     apy_key=os.getenv('API_KEY'),
39:     deps_type=FlagDependencies,
40:     ersult_type=ZapperResult,
41:     system_prompt=(
42:     'You are an expert software debugging assistant specializing in programming error analysis. '
43:     'Your task is to analyze error tracebacks and provide structured, actionable advice. '
44:     )
45: )
46: 
47: @bug_zapper.tool

================
File: agents/file_writer_agent.py
================
 1: # file_writer_agent.py
 2: from uagents import Agent, Context, Model
 3: import os
 4: import json
 5: import black 
 6: 
 7: class FileWriteRequest(Model):
 8:     file_path: str
 9:     content: str
10: 
11: class FileWriteResponse(Model):
12:     success: bool
13:     message: str
14: 
15: class ErrorCorrectionRequest(Model):
16:     response: dict
17: 
18: class ErrorCorrectionResponse(Model):
19:     success: bool
20:     message: str
21: 
22: file_writer = Agent(name="file_writer", seed="file_writer_seed", port=8000, endpoint="http://localhost:8000/submit")
23: 
24: 
25: @file_writer.on_event("startup")
26: async def startup(ctx: Context):
27:     ctx.logger.info(f"Starting up {file_writer.name} agent @ {file_writer.address}")
28: 
29: @file_writer.on_message(model=FileWriteRequest)
30: async def write_to_file(ctx: Context, sender: str, msg: FileWriteRequest):
31:     try:
32:         with open(msg.file_path, 'w') as file:
33:             file.write(msg.content)
34:         ctx.logger.info(f"Successfully wrote to file: {msg.file_path}")
35:         await ctx.send(sender, FileWriteResponse(success=True, message=f"File {msg.file_path} updated successfully"))
36:     except Exception as e:
37:         error_message = f"Error writing to file {msg.file_path}: {str(e)}"
38:         ctx.logger.error(error_message)
39:         await ctx.send(sender, FileWriteResponse(success=False, message=error_message))
40:         
41: @file_writer.on_message(model=ErrorCorrectionRequest)
42: async def apply_error_correction(ctx: Context, sender: str, msg: ErrorCorrectionRequest):
43:     try:
44:         response = msg.response
45:         file_path = os.path.join(response['where']['repository_path'], response['where']['file_name'])
46:         line_number = int(response['where']['line_number'])
47:         suggested_code = response['how']['suggested_code_solution']
48: 
49:         with open(file_path, 'r', encoding='utf-8') as file:
50:             lines = file.readlines()
51: 
52:         if 0 < line_number <= len(lines):
53:             stripped_line = lines[line_number - 1].strip()
54:             num_whitespace = len(lines[line_number - 1]) - len(stripped_line)
55:             lines[line_number - 1] = " " * num_whitespace + suggested_code
56: 
57:             with open(file_path, 'w', encoding='utf-8') as file:
58:                 file.writelines(lines)
59:             '''
60:             #after writing, we want to reformat the file
61:             with open(file_path, 'r') as file:
62:                 content = file.read()
63:                 formatted_content = black.format(content, mode=black.FileMode())
64:                 
65:             with open(file_path, 'w') as file:
66:                 file.write(formatted_content)
67:             '''
68:             ctx.logger.info(f"Successfully applied correction to file: {file_path}")
69:             await ctx.send(sender, FileWriteResponse(success=True, message=f"File {file_path} updated successfully"))
70:         else:
71:             raise IndexError("Line number out of range")
72:     except Exception as e:
73:         error_message = f"Error applying correction: {str(e)}"
74:         ctx.logger.error(error_message)
75:         await ctx.send(sender, FileWriteResponse(success=False, message=error_message))
76: 
77: @file_writer.on_rest_post("/apply_correction", ErrorCorrectionRequest, ErrorCorrectionResponse)
78: async def handle_error_correction(ctx: Context, request: ErrorCorrectionRequest) -> ErrorCorrectionResponse:
79:     try:
80:         await apply_error_correction(ctx, file_writer.address, request)
81:         return ErrorCorrectionResponse(success=True, message="Error correction applied successfully")
82:     except Exception as e:
83:         print(str(e))
84:         return ErrorCorrectionResponse(success=False, message=f"Error applying correction: {str(e)}")
85: 
86: 
87: if __name__ == "__main__":
88:     print("Starting file writer agent server on http://localhost:8000")
89:     file_writer.run()

================
File: agents/zapper.py
================
  1: from collections import defaultdict
  2: from langchain_core.runnables.utils import Output
  3: from langchain_groq import ChatGroq
  4: from langchain_openai import ChatOpenAI
  5: from langchain_anthropic import ChatAnthropic
  6: from langchain_ollama import ChatOllama
  7: from typing import Annotated, List, Optional
  8: from langgraph.graph.state import CompiledStateGraph
  9: from typing_extensions import TypedDict
 10: from langgraph.graph import StateGraph, START, END
 11: from langgraph.graph.message import add_messages
 12: from langchain_core.output_parsers import PydanticOutputParser, JsonOutputParser
 13: from langchain_core.prompts import ChatPromptTemplate
 14: from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
 15: from langchain_core.tools import tool
 16: from langgraph.types import interrupt
 17: from dotenv import load_dotenv
 18: import os
 19: import subprocess
 20: import tomllib
 21: from pydantic import SecretStr, BaseModel, Field
 22: from utils.utils import calculate_semantic_similarity
 23: from cli.child_terminal import ChildTerminal
 24: 
 25: 
 26: load_dotenv()
 27: 
 28: 
 29: class GraphState(TypedDict):
 30:     messages: Annotated[list, add_messages]
 31:     next: Optional[str]
 32: 
 33: 
 34: class ErrorExplanation(BaseModel):
 35:     error_type: str = Field(description="The type of error encountered")
 36:     explanation: str = Field(description="Detailed explanation of the error")
 37:     suggested_fixes: List[str] = Field(description="List of potential fixes for the error")
 38:     code_segments: List[str] = Field(description="List of code segments to fix the errors mentioned")
 39: 
 40: 
 41: def explainer_llm_selection():
 42:     #with open("config.toml", "rb") as f:
 43:         #config = tomllib.load(f)
 44:     api_key = os.getenv('GROQ_API_KEY')
 45:     if not api_key:
 46:         raise ValueError("GROQ_API_KEY environment variable is not set")
 47:     return ChatGroq(
 48:             model="llama-3.3-70b-versatile",
 49:             api_key= SecretStr(api_key),
 50:             temperature=0,
 51:             stop_sequences=None,
 52: 
 53:     )
 54: def corrector_llm_selection():
 55:     api_key = os.getenv('GROQ_API_KEY')
 56:     if not api_key:
 57:         raise ValueError("GROQ_API_KEY environment variable is not set")
 58:     return ChatGroq(
 59:             model="llama-3.3-70b-versatile",
 60:             api_key= SecretStr(api_key),
 61:             temperature=0,
 62:             stop_sequences=None)
 63: 
 64: class Zapper:
 65:     llm: ChatGroq | ChatOpenAI | ChatAnthropic | ChatOllama
 66:     state: GraphState
 67:     graph_builder: StateGraph
 68:     graph: CompiledStateGraph
 69:     def __init__(self, terminal_session: Optional[ChildTerminal]):
 70:         self.explainer_llm = explainer_llm_selection()
 71:         self.corrector_llm = corrector_llm_selection()
 72:         self.graph_builder = StateGraph(GraphState)
 73:         self.parser = PydanticOutputParser(pydantic_object=ErrorExplanation)
 74:         self.child_terminal = terminal_session
 75:         self.init_graph(self.graph_builder)
 76: 
 77: 
 78:     def prompt(self, state: GraphState):
 79:         return { "messages": [self.llm.invoke(state["messages"])]}
 80: 
 81:     def explain_error(self, state: GraphState):
 82:         """This method should be one of the nodes that generate the response for the code.
 83:            This node requires there to be a traceback, error_information, and code context in the state to run.
 84:         """
 85:         parse = JsonOutputParser(pydantic_object=ErrorExplanation)
 86:         prompt = ChatPromptTemplate.from_messages([
 87:                         ("system", "You are an expert software debugging assistant specializing in code error analysis. Your task is to analyze error tracebacks and provide structured, actionable advice. Follow these steps precisely:"),
 88:                         ("system", "1. Analyze the provided error traceback and original error message.\n2. Identify the source of the error within the repository structure.\n3. Explain the error concisely in natural language.\n4. Provide specific, actionable suggestions for resolving the error."),
 89:                         ("system", "Generate code that would fix the given errors and return a list of code segments, correctly formatted in the appropriate language, following the syntax rules of the lanaguage."),
 90:                         ("system", "{format_instructions"),
 91:                         ("user", "{traceback}, {error_information}, {context}")
 92:                     ])
 93:         error_object = state["messages"][-1]
 94:         traceback, error_information, context = error_object["traceback"], error_object["error_information"], error_object["context"]
 95:         formatted_prompt = prompt.format_messages(
 96:             format_instructions=self.parser.get_format_instructions(),
 97:             traceback=traceback,
 98:             error_information=error_information,
 99:             context=context
100:         )
101:         if traceback and error_information:
102:             response = self.llm.invoke(formatted_prompt)
103: 
104:             parsed_response = self.parser.parse(str(response.content))
105:         else:
106:             parsed_response = None
107:         error_type, explanation, suggested_fixes, code_segments = "", "", "", ""
108:         if parsed_response:
109:             model_dump = parsed_response.model_dump()
110:             error_type, explanation, suggested_fixes, code_segments = model_dump["error_type"], model_dump["explanation"], model_dump["suggested_fixes"], model_dump["code_segments"]
111:         return {"messages": state["messages"] + [{
112:             "role": "assistant",
113:             #content": parsed_response.model_dump() if parsed_response else ""
114:             "error_type": error_type,
115:             "explanation": explanation,
116:             "suggested_fixes": suggested_fixes,
117:             "code_segments": code_segments
118:         }]}
119: 
120:     def repomix(self, state: GraphState, flag):
121: 
122: 
123: 
124:     def run_branch(self, state: GraphState) -> dict:
125:         command = state["messages"][-1]
126:         try:
127:             subprocess.run(command, capture_output=True, check=True, text=True)
128:         except subprocess.CalledProcessError as error:
129:             traceback: str = error.stderr if error.stderr else str(error)
130:             error_information = str(error)
131:             return {
132:                 "messages": state["messages"] + [
133:                     {
134:                         "traceback": traceback,
135:                         "error_information": error_information
136:                     } # the error traceback and error information are added to the graph messages
137:                 ],
138:                 "next": "analyze_branch",
139:             }
140:         return {
141:             "messages": state["messages"] + [
142:                 {"traceback": None,
143:                 "error_information": None
144:                 }# the error traceback and error information are added to the graph messages
145:             ],
146:             "next": "analyze_branch",
147:         }
148: 
149:     def analyze_branch(self, state: GraphState):
150:         error_object = state["messages"][-1]
151:         traceback, error_information = error_object["traceback"], error_object["error_information"]
152: 
153:     def evaluate_input(self, state: GraphState) -> dict:
154:         last_message = state["messages"][-1]
155: 
156:         # Extract content based on message type
157:         if isinstance(last_message, tuple):
158:             message_content = last_message[1]
159:         elif hasattr(last_message, 'content'):
160:             message_content = last_message.content
161:         else:
162:             message_content = str(last_message)
163: 
164:         # Return state dict and include next step in metadata
165:         if calculate_semantic_similarity("help", message_content) > 0.5:
166:             return {
167:                 "messages": state["messages"] + [
168:                     AIMessage(content="Routing to help...")
169:                 ],
170:                 "next": "help_branch",
171:             }
172:         elif calculate_semantic_similarity("fix", message_content) > 0.5 or \
173:                 calculate_semantic_similarity("debug", message_content) > 0.5:
174:             return {
175:                 "messages": state["messages"] + [
176:                     AIMessage(content="Routing to fix...")
177:                 ],
178:                 "next": "fix_branch",
179:             }
180:         else:
181:             return {
182:                 "messages": state["messages"] + [
183:                     AIMessage(content="Completing interaction...")
184:                 ],
185:                 "next": "done_branch",
186:             }
187: 
188:     def help_branch(self, state: GraphState) -> dict:
189:         # Print the help message
190:         help_message = ("I'm here to help! What would you like to know?\n"
191:                         "- Type 'fix' to get help fixing an issue\n"
192:                         "- Type 'help' for general assistance\n"
193:                         "- Type 'done' to finish")
194:         return {
195:             "messages": state["messages"] + [
196:                 AIMessage(content=help_message)
197:             ],
198:             "next": "wait_for_input",  # Transition to wait state
199:         }
200: 
201:     def fix_branch(self, state: GraphState) -> dict:
202: 
203:         fix_message = ("Let's fix that issue!\n"
204:                         "- Describe your problem in detail\n"
205:                         "- Type 'help' if you need different assistance\n"
206:                         "- Type 'done' when the issue is resolved")
207:         return {
208:             "messages": state["messages"] + [
209:                 AIMessage(content=fix_message)
210:             ],
211:             "next": "wait_for_input",  # Transition to wait state
212:         }
213: 
214:     def done_branch(self, state: GraphState) -> dict:
215:         return {
216:             "messages": state["messages"] + [
217:                 AIMessage(content="Thanks for using the assistance! Goodbye!")
218:             ],
219:             "next": END, # end of conversation
220:         }
221: 
222:     def wait_for_input(self, state: GraphState) -> dict:
223:             """Wait for user input before continuing"""
224:             # Get user input
225:             user_input = input("You: ")
226: 
227:             # Add user input to state
228:             return {
229:                 "messages": state["messages"] + [
230:                     HumanMessage(content=user_input)
231:                 ],
232:                 "next": self.determine_next_step(user_input),
233:             }
234:     def determine_next_step(self, user_input: str) -> str:
235:             """Determine next step based on user input"""
236:             if calculate_semantic_similarity("done", user_input) > 0.5:
237:                 return "done_branch"
238:             elif calculate_semantic_similarity("help", user_input) > 0.5:
239:                 return "help_branch"
240:             elif calculate_semantic_similarity("fix", user_input) > 0.5:
241:                 return "fix_branch"
242:             else:
243:                 return "help_branch"
244: 
245:     def cyclic_router(self, state: GraphState):
246:         """
247:         Routes between help, fix, and done states based on the last message
248:         """
249:         try:
250:             # Get the last message from the state
251:             message = state["messages"][-1][1]  # Assuming message is a tuple of (role, content)
252:             print(f"Cyclic router processing: {message}")
253: 
254:             # Check message content and route accordingly
255:             if calculate_semantic_similarity("done", message) > 0.5:
256:                 print("Routing to done_branch")
257:                 return "done_branch"
258:             elif calculate_semantic_similarity("help", message) > 0.5:
259:                 print("Routing to help_branch")
260:                 return "help_branch"
261:             elif calculate_semantic_similarity("fix", message) > 0.5 or \
262:                  calculate_semantic_similarity("debug", message) > 0.5:
263:                 print("Routing to fix_branch")
264:                 return "fix_branch"
265:             else:
266:                 # Default to help branch if we can't determine the intent
267:                 print("Default routing to help_branch")
268:                 return "help_branch"
269:         except Exception as e:
270:             print(f"Error in cyclic_router: {e}")
271:             return "help_branch"  # Default fallback
272: 
273: 
274:     def init_graph(self, graph_builder: StateGraph):
275:         # Add nodes
276:         graph_builder.add_node("entry_point", self.evaluate_input)
277:         graph_builder.add_node("help_branch", self.help_branch)
278:         graph_builder.add_node("fix_branch", self.fix_branch)
279:         graph_builder.add_node("wait_for_input", self.wait_for_input)
280:         graph_builder.add_node("done_branch", self.done_branch)
281: 
282:         # Define edges
283:         graph_builder.add_conditional_edges(
284:             "entry_point",
285:             lambda x: x["next"],
286:             {
287:                 "help_branch": "help_branch",
288:                 "fix_branch": "fix_branch",
289:                 "done_branch": "done_branch",
290:                 "wait_for_input": "wait_for_input"
291:             }
292:         )
293: 
294:         # Add edges from wait_for_input
295:         graph_builder.add_conditional_edges(
296:             "wait_for_input",
297:             lambda x: x["next"],
298:             {
299:                 "help_branch": "help_branch",
300:                 "fix_branch": "fix_branch",
301:                 "done_branch": "done_branch"
302:             }
303:         )
304: 
305:         # Add edges from help and fix branches
306:         for branch in ["help_branch", "fix_branch"]:
307:             graph_builder.add_conditional_edges(
308:                 branch,
309:                 lambda x: x["next"],
310:                 {
311:                     "wait_for_input": "wait_for_input",
312:                     "done_branch": "done_branch"
313:                 }
314:             )
315: 
316:         # Terminal edge
317:         graph_builder.add_edge("done_branch", END)
318: 
319:         # Set entry point
320:         graph_builder.set_entry_point("entry_point")
321: 
322:         # Compile graph
323:         self.graph = graph_builder.compile()
324: 
325:     def stream_graph_updates(self, user_input: str):
326:         for event in self.graph.stream({
327:             "messages": [("user", user_input)]
328:         }):
329:             for key, value in event.items():
330:                 if "messages" in value and value["messages"]:
331:                     message = value["messages"][-1]
332:                     if isinstance(message, tuple):
333:                         print(f"Assistant: {message[1]}")
334:                     else:
335:                         print(f"Assistant: {message}")
336:     def return_graph_updates(self, error_input: str):
337:         responses = []
338:         for event in self.graph.stream({"messages": [("user", error_input)]}):
339:             llm_response = defaultdict()
340:             for value in event.values():
341:                 response = value["messages"][-1]["content"]
342:                 llm_response["error_type"] = response["error_type"]
343:                 llm_response["explanation"] = response["explanation"]
344:                 llm_response["suggested_fixes"] = response["suggested_fixes"]
345:                 llm_response["code_example"] = response["code_example"]
346:             print(llm_response["code_example"])
347:             responses.append(llm_response)
348:         return responses
349: 
350:     #tool
351:     def apply_fixes(self, code_fixes: List[str], files: List[str]):
352:         code_fixes_and_files = zip(code_fixes, files)
353:         for fix in code_fixes_and_files:
354:             # apply fix
355:             print(fix)
356: 
357: def main():
358:     zapper = Zapper()
359:     #zapper.stream_graph_updates("tell me about langchain")
360: 
361: 
362: if __name__ == "__main__":
363:     main()

================
File: cli/child_terminal.py
================
  1: from process_monitor import ProcessMonitor
  2: from typing import Optional
  3: import zmq
  4: import platform
  5: import base64
  6: import zlib
  7: import subprocess
  8: import traceback
  9: import time
 10: import os
 11: 
 12: class ChildTerminal:
 13:     monitor: Optional[ProcessMonitor]
 14:     def __init__(self, port=5555, terminal_app=None, session_name='zapper_session'):
 15:         self.context = zmq.Context()
 16:         self.publisher = self.context.socket(zmq.PUB)
 17:         self.publisher.bind(f"tcp://*:{port}")
 18:         self.system = platform.system()
 19:         self.session_name = session_name
 20:         self.terminal_process = None
 21:         self.monitor = None
 22:         self.tmux_stack = [""]
 23:         self.last_stdout = ""
 24:         self.last_stderr = ""
 25:         self.error_log_file = f"/tmp/{session_name}_stderr.log"
 26: 
 27:     def send_code_segment(self, code_data):
 28:         """
 29:         Send code segments with metadata
 30:         code_data = {
 31:             'file_path': 'path/to/file',
 32:             'code': 'actual code content',
 33:             'metadata': {...},
 34:             'action': 'analyze/edit/debug'
 35:         }
 36:         """
 37:         # Compress the code content
 38:         compressed_code = base64.b64encode(
 39:             zlib.compress(code_data['code'].encode())
 40:         ).decode()
 41:         code_data['code'] = compressed_code
 42: 
 43:         # Send the data
 44:         self.publisher.send_json(code_data)
 45: 
 46:     def open_new_terminal(self):
 47:         """Create an interactive terminal session with proper error handling"""
 48:         try:
 49:             self.kill_tmux_session()
 50: 
 51:             subprocess.run(['tmux', 'new-session', '-d', '-s', self.session_name])
 52:             subprocess.run(['tmux', 'pipe-pane', '-t', self.session_name,f'2> {self.error_log_file}'])
 53: 
 54:             # Open a new terminal window and attach to the tmux session
 55:             if platform.system() == "Darwin":  # macOS
 56:                 apple_script = f'''
 57:                     tell application "Terminal"
 58:                         do script "tmux attach-session -t {self.session_name}"
 59:                     end tell
 60:                 '''
 61:                 subprocess.Popen(['osascript', '-e', apple_script])
 62:             elif platform.system() == "Linux":
 63:                 subprocess.Popen([
 64:                     'gnome-terminal', '--', 'tmux', 'attach-session', '-t', self.session_name
 65:                 ])
 66:             else:
 67:                 raise NotImplementedError("Windows not yet supported")
 68: 
 69:             # Allow some time for tmux session to start
 70:             time.sleep(1)
 71: 
 72:             return True
 73:         except Exception as e:
 74:             print(f"Error creating tmux session: {e}")
 75:             traceback.print_exc()
 76:             return False
 77: 
 78:     def kill_tmux_session(self):
 79:         """Kill the tmux session if it exists"""
 80:         try:
 81:             # Check if session exists
 82:             result = subprocess.run(
 83:                 ['tmux', 'has-session', '-t', self.session_name],
 84:                 capture_output=True
 85:             )
 86:             if result.returncode == 0:  # Session exists
 87:                 subprocess.run(['tmux', 'kill-session', '-t', self.session_name])
 88:         except Exception as e:
 89:             print(f"Error killing tmux session: {e}")
 90: 
 91:     def read_tmux_output(self):
 92:         """Read output from the tmux session"""
 93:         try:
 94:             # Capture the entire pane content with history
 95:             result = subprocess.run(
 96:                 ['tmux', 'capture-pane', '-S -100', '-t', self.session_name, '-p'],  # Get more history
 97:                 capture_output=True,
 98:                 text=True
 99:             )
100: 
101:             current_output = self.clean_tmux_output(result.stdout)
102:             lines = current_output.split('\n')
103: 
104:             error_lines = []
105:             in_error = False
106:             buffer_lines = []  # Keep recent lines in buffer
107: 
108:             for line in lines:
109:                 # Keep a buffer of recent lines
110:                 buffer_lines.append(line)
111:                 if len(buffer_lines) > 5:  # Keep last 5 lines
112:                     buffer_lines.pop(0)
113: 
114:                 if 'Traceback' in line or any(err in line for err in [
115:                     'SyntaxError:', 'NameError:', 'TypeError:', 'ValueError:',
116:                     'ImportError:', 'AttributeError:', 'RuntimeError:',
117:                     'IndentationError:', 'TabError:'
118:                 ]):
119:                     in_error = True
120:                     # Add the buffer lines for context
121:                     error_lines.extend(buffer_lines)
122:                     continue
123: 
124:                 if in_error:
125:                     error_lines.append(line)
126:                     # Look for patterns that indicate end of error
127:                     if not line.strip() or line.startswith(('$ ', '> ', 'zap>')):
128:                         in_error = False
129: 
130:             error_text = '\n'.join(line for line in error_lines if line.strip())
131: 
132:             if error_text and error_text != self.last_stderr:
133:                 self.last_stderr = error_text
134:                 return {
135:                     'stdout': "",
136:                     'stderr': error_text
137:                 }
138: 
139:             return None
140: 
141:         except Exception as e:
142:             print(f"Error reading tmux session: {e}")
143:             traceback.print_exc()
144:             return None
145: 
146:     def clean_tmux_output(self, raw_output: str) -> str:
147:         """Clean and format tmux output by removing ANSI escape sequences and extra whitespace"""
148:         import re
149: 
150:         # Remove ANSI escape sequences
151:         ansi_escape = re.compile(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])')
152:         # Remove unicode characters commonly used in prompts
153:         unicode_chars = re.compile(r'[\ue0b0-\ue0b3\ue5ff\ue615\ue606\uf48a\uf489\ue0a0]')
154: 
155:         # Clean the output
156:         cleaned = ansi_escape.sub('', raw_output)
157:         cleaned = unicode_chars.sub('', cleaned)
158: 
159:         # Preserve indentation but remove other whitespace
160:         lines = []
161:         for line in cleaned.split('\n'):
162:             indent = len(line) - len(line.lstrip())
163:             cleaned_line = line.strip()
164:             if cleaned_line:
165:                 lines.append(' ' * indent + cleaned_line)
166: 
167:         return '\n'.join(lines)
168:     def is_terminal_active(self) -> bool:
169:         """Check if terminal session is active and valid"""
170:         return (self.terminal_process is not None and
171:                 self.terminal_process.poll() is None)
172:     def send_to_terminal(self, command: str) -> Optional[str]:
173:         """Send a command to the tmux session"""
174:         try:
175:             subprocess.run(['tmux', 'send-keys', '-t', self.session_name, command, 'C-m'])
176:             return "Command sent"
177:         except Exception as e:
178:             print(f"Error sending to tmux session: {e}")
179:             return None

================
File: cli/cli.py
================
  1: import click
  2: import sys
  3: import cmd
  4: from process_monitor import ProcessMonitor
  5: from listener import Listener
  6: from child_terminal import ChildTerminal
  7: from agents.zapper import Zapper
  8: import subprocess
  9: import shlex
 10: import os
 11: from langchain_core.messages import HumanMessage
 12: import traceback
 13: 
 14: class ZapShell(cmd.Cmd):
 15:     intro = 'Welcome to the Zap CLI. Type help or ? to list commands.\n'
 16:     prompt = 'zap> '
 17: 
 18:     def __init__(self):
 19:         super().__init__()
 20:         self.ctx = None
 21:         self.zapper = None
 22:         self.child_terminal = None
 23:         self.zapper = Zapper()
 24: 
 25:     # Command definitions
 26:     def do_hello(self, arg):
 27:         """Say hello"""
 28:         click.echo('Hello!')
 29: 
 30:     def do_echo(self, arg):
 31:         """Echo the input"""
 32:         click.echo(arg)
 33: 
 34:     def do_exit(self, arg):
 35:         """Exit the application"""
 36:         click.echo('Goodbye!')
 37:         if self.child_terminal:
 38:             if self.child_terminal.monitor:
 39:                 self.child_terminal.monitor.is_running = False
 40:             if self.child_terminal.terminal_process:
 41:                 self.child_terminal.terminal_process.terminate()
 42:             self.child_terminal.kill_tmux_session()
 43:         click.echo('Goodbye!')
 44:         return True
 45:         return True
 46: 
 47:     def do_start(self, arg):
 48:         """Start up the terminal session using tmux"""
 49:         self.listener = Listener()
 50:         self.listener.start()
 51:         #self.zapper.run_subscriber()
 52:         self.child_terminal= ChildTerminal(session_name='zapper_session')
 53:         if self.child_terminal.open_new_terminal():
 54:             self.child_terminal.monitor = ProcessMonitor(self.child_terminal)
 55:             self.child_terminal.monitor.start_monitoring()
 56:         else:
 57:             click.echo("Failed to start terminal session")
 58: 
 59:     def do_debug(self, entrypoint):
 60:         try:
 61:             if not entrypoint:
 62:                 raise Exception("No command provided")
 63:             subprocess.run(entrypoint.split(), capture_output=True, check=True, text=True)
 64:             print("No error with your program! :)")
 65:         except subprocess.CalledProcessError as error:
 66:             traceback: str = error.stderr if error.stderr else str(error)
 67:             print(traceback)
 68:         except Exception as e:
 69:             print(e)
 70: 
 71:     def do_helper(self, arg):
 72:         if self.zapper:
 73:             try:
 74:                 initial_state = {
 75:                     "messages": [HumanMessage(content="help")],
 76:                     "next": "help_branch",
 77:                 }
 78:                 seen_messages = set()
 79: 
 80:                 for event in self.zapper.graph.stream(initial_state):
 81:                     for value in event.values():
 82:                         if "messages" not in value:
 83:                             continue
 84: 
 85:                         # Get only new messages
 86:                         new_messages = [
 87:                             msg for msg in value["messages"]
 88:                             if msg.content not in seen_messages
 89:                         ]
 90: 
 91:                         for message in new_messages:
 92:                             if not hasattr(message, 'content'):
 93:                                 continue
 94: 
 95:                             # Add to seen messages
 96:                             seen_messages.add(message.content)
 97: 
 98:                             # Print with appropriate prefix
 99:                             if message.type == "assistant":
100:                                 print(f"\nAssistant: {message.content}")
101:                             elif message.type == "human":
102:                                 print(f"\nYou: {message.content}")
103: 
104:                             # If message contains file context, format it nicely
105:                             #if "file_context" in value:
106:                                 #self.format_file_context(value["file_context"])
107:             except Exception as e:
108:                 print(f"Error in helper: {e}")
109:                 traceback.print_exc()
110:         else:
111:             print("The zapper hasn't been initialized :( please try again")
112:             return
113: 
114:     def do_run(self, arg):
115:         command = input()
116:         try:
117:             process = subprocess.run(command.split(), capture_output=True, check=True, text=True)
118:             output = process.stdout if process.stdout else ""
119:             print(output)
120:         except subprocess.CalledProcessError as error:
121:             traceback: str = error.stderr if error.stderr else str(error)
122:             error_information = str(error)
123:             print(traceback)
124:             print(error_information)
125:         except FileNotFoundError as e:
126:             print(e)
127: 
128:     def do_send(self, arg):
129:         """Send a command to the terminal"""
130:         if not self.child_terminal or not self.child_terminal.is_terminal_active():
131:             click.echo("No active terminal session. Use 'start' first.")
132:             return
133:         response = self.child_terminal.send_to_terminal(arg)
134:         if response:
135:             click.echo(f"Command sent: {response}")
136:     def do_quit(self, arg):
137:         """Exit the application"""
138:         return self.do_exit(arg)
139: 
140:     # Shortcut for exit
141:     do_EOF = do_quit
142: 
143:     def default(self, line):
144:         """Handle unknown commands"""
145:         if self.child_terminal and self.child_terminal.is_terminal_active():
146:             self.do_send(line)
147:         else:
148:             click.echo(f"Unknown command: {line}")
149:         click.echo(f"Unknown command: {line}")
150:     def precmd(self, line):
151:             """Check terminal status before each command"""
152:             if self.child_terminal and not self.child_terminal.is_terminal_active():
153:                 click.echo("Terminal session ended unexpectedly")
154:             return line
155: 
156: @click.group(invoke_without_command=True)
157: @click.pass_context
158: def cli(ctx):
159:     """Zap CLI - An interactive command line tool"""
160:     if ctx.invoked_subcommand is None:
161:         # Start the interactive shell
162:         shell = ZapShell()
163:         shell.ctx = ctx
164:         shell.cmdloop()
165: 
166: 
167: @cli.command()
168: def version():
169:     """Show the version"""
170:     click.echo('Zap CLI v0.1.0')
171: 
172: def main():
173:     try:
174:         cli()
175:     except KeyboardInterrupt:
176:         click.echo("\nGoodbye!")
177:         sys.exit(0)
178: 
179: if __name__ == '__main__':
180:     main()

================
File: cli/listener.py
================
 1: # auto_debugger.py
 2: import time
 3: import zmq
 4: import threading
 5: import sys
 6: import traceback
 7: 
 8: #from relational import relational_error_parsing_function
 9: 
10: class Listener:
11:     def __init__(self, port=5555, max_stack_size=500):
12:         self.context = zmq.Context()
13:         self.running = False
14:         self.subscriber_thread = None
15:         self.subscriber = self.context.socket(zmq.SUB)
16:         self.subscriber.connect(f"tcp://127.0.0.1:{port}")
17:         self.subscriber.setsockopt_string(zmq.SUBSCRIBE, "")
18:         self.max_stack_size = max_stack_size
19:         self.stdout_stack = [""]
20:         self.stderr_stack = [""]
21: 
22:     def start(self):
23:         """Start the publisher thread"""
24:         self.running = True
25:         self.subscriber_thread = threading.Thread(target=self.run_subscriber)
26:         self.subscriber_thread.daemon = True
27:         self.subscriber_thread.start()
28:         print("ZMQ publisher thread started")
29: 
30:     def manage_stack(self, stack, new_item):
31:         """Manage stack size and add new item"""
32:         if len(stack) >= self.max_stack_size:
33:             stack.pop(0)  # Remove oldest item
34:         stack.append(new_item)
35: 
36:     def run_subscriber(self):
37:         while self.running:
38:             try:
39:                 message = self.subscriber.recv_json(flags=zmq.NOBLOCK)
40:                 if isinstance(message, dict) and message.get('type') == 'tmux_output':
41:                     tmux_pane_output = message.get('data')
42:                     if tmux_pane_output and tmux_pane_output.get('stderr'):
43:                         current_stderr = tmux_pane_output['stderr']
44: 
45:                         # Only process if we have new stderr content
46:                         if current_stderr and current_stderr != self.stderr_stack[-1]:
47:                             # Print full error stack with formatting
48:                             print("\n" + "="*50)
49:                             print("Error Detected:")
50:                             print("="*50)
51:                             print(current_stderr)
52:                             print("="*50)
53:                             print("\nzap> ", end='', flush=True)
54: 
55:                             # Update the stack
56:                             self.manage_stack(self.stderr_stack, current_stderr)
57: 
58:             except zmq.Again:
59:                 time.sleep(0.1)
60:             except Exception as e:
61:                 print(f"Error in subscriber: {e}")
62:                 traceback.print_exc()
63:                 time.sleep(0.1)
64: 
65:     def stop(self):
66:         """Stop publisher threads"""
67:         self.running = False
68:         if self.subscriber_thread:
69:             self.subscriber_thread.join()
70:         self.context.term()
71: 
72: 
73: 
74: #if __name__ == "__main__":

================
File: cli/process_monitor.py
================
 1: import threading
 2: import time
 3: 
 4: class ProcessMonitor:
 5:     def __init__(self, child_terminal):
 6:         self.child_terminal = child_terminal
 7:         self.monitor_thread = None
 8:         self.poll_interval = 1
 9:         self.is_running = False
10: 
11:     def start_monitoring(self):
12:         self.is_running = True
13:         self.monitor_thread = threading.Thread(target=self.monitor_tmux)
14:         self.monitor_thread.daemon = True
15:         self.monitor_thread.start()
16:         print('monitor thread starting')
17:     def monitor_tmux(self):
18:         while self.is_running:
19:             try:
20:                 output = self.child_terminal.read_tmux_output()
21:                 if output:  # Only send if there are changes
22:                     self.child_terminal.publisher.send_json({
23:                         'type': 'tmux_output',
24:                         'data': output,
25:                         'timestamp': time.time()
26:                     })
27:                 time.sleep(self.poll_interval)
28:             except Exception as e:
29:                 print(f"Error in monitor: {e}")
30:                 time.sleep(self.poll_interval)

================
File: handlers/fastapi_handlers.py
================
 1: import os
 2: import subprocess
 3: import time
 4: import select
 5: import re
 6: from typing import Dict, List
 7: import click
 8: from process.process import process
 9: 
10: def parse_fastapi_error(error_info: str) -> Dict[str, List[str]]:
11:     endpoints = []
12:     error_types = []
13:     
14:     # Pattern for connection errors
15:     error_pattern = r'Error accessing endpoint (/\w+): (.+)'
16:     
17:     matches = re.findall(error_pattern, error_info)
18:     
19:     for match in matches:
20:         endpoint, error_type = match
21:         endpoints.append(endpoint)
22:         error_types.append(error_type)
23: 
24:     # If no matches found, check for server startup error
25:     if not matches:
26:         server_error_match = re.search(r'Server error: (.+)', error_info)
27:         if server_error_match:
28:             endpoints.append("Server Startup")
29:             error_types.append(server_error_match.group(1))
30: 
31:     return {
32:         "endpoints": list(dict.fromkeys(endpoints)),
33:         "error_types": list(dict.fromkeys(error_types))
34:     }
35: 
36: def compile_project(project_dir):
37:     """Run the FastAPI project in the specified directory and capture any errors."""
38:     os.chdir(project_dir)
39:     process = subprocess.Popen(
40:         ["python", "src/app/main.py", "--log-level", "error"],
41:         stdout=subprocess.DEVNULL,
42:         stderr=subprocess.PIPE,
43:         text=True,
44:     )
45:     
46:     output = []
47:     error_detected = False
48:     start_time = time.time()
49:     
50:     while True:
51:         reads = [process.stdout.fileno(), process.stderr.fileno()]
52:         ret = select.select(reads, [], [], 0.5)
53: 
54:         for fd in ret[0]:
55:             if fd == process.stdout.fileno():
56:                 line = process.stdout.readline()
57:                 output.append(line)
58:             if fd == process.stderr.fileno():
59:                 line = process.stderr.readline()
60:                 output.append(line)
61: 
62:         full_output = "".join(output)
63:         if "ERROR:" in full_output and not error_detected:
64:             error_detected = True
65: 
66:         # Stop capturing after 30 seconds or if an error is detected
67:         if error_detected or (time.time() - start_time > 30):
68:             break
69: 
70:         if process.poll() is not None:
71:             break
72:         
73:     process.terminate()
74:     try:
75:         process.wait(timeout=5)
76:     except subprocess.TimeoutExpired:
77:         process.kill()
78:     
79:     # Capture any remaining output
80:     stdout, stderr = process.communicate()
81:     output.extend([stdout, stderr])
82:     
83:     full_output = "".join(output)
84:     return full_output
85: 
86: def process_error(error_message):
87:     """Process the error message and generate human-readable explanation."""
88:     error_data = parse_fastapi_error(error_message)
89:     
90:     if not error_data['endpoints'] and not error_data['error_types']:
91:         return "Couldn't extract error information from the error message."
92: 
93:     # Construct context for explanation
94:     context = f"FastAPI server errors:\n"
95:     for endpoint, error_type in zip(error_data['endpoints'], error_data['error_types']):
96:         context += f"Endpoint {endpoint} encountered error: {error_type}\n"
97: 
98:     explanation = process(error_message, context)
99:     return explanation

================
File: process/agent_handler.py
================
 1: # agent_handler.py
 2: from agents.file_writer_agent import FileWriteRequest, FileWriteResponse, file_writer
 3: 
 4: async def apply_changes(file_path: str, proposed_changes: str) -> bool:
 5:     file_write_request = FileWriteRequest(
 6:         file_path=file_path,
 7:         content=proposed_changes
 8:     )
 9:     
10:     # Send the request to the file writer agent
11:     result = await file_writer.send(file_write_request)
12:     
13:     if isinstance(result, FileWriteResponse):
14:         if result.success:
15:             print("Changes have been applied to the file by the agent.")
16:             return True
17:         else:
18:             print("Failed to apply changes. Error:", result.message)
19:             return False
20:     else:
21:         print("Unexpected response from file writer agent.")
22:         return False
23: 
24: def run_file_writer_agent():
25:     file_writer.run()

================
File: process/process.py
================
 1: # [START process/process.py]
 2: from groq import Groq
 3: import os
 4: import json
 5: from dotenv import load_dotenv
 6: from terminalout.terminal import terminalstep1
 7: 
 8: load_dotenv()
 9: 
10: def process(traceback_message: str, original_error_information: str, context: str) -> object:
11:   client = Groq(api_key=os.getenv("API"))
12: 
13:   chat_completion = client.chat.completions.create(
14:     messages=[
15:         {
16:           "role": "system",
17:           "content": "You are an expert software debugging assistant specializing in Python error analysis. Your task is to analyze error tracebacks and provide structured, actionable advice. Follow these steps precisely:"
18:         },
19:         {
20:           "role": "system",
21:           "content": "1. Analyze the provided error traceback and original error message.\n2. Identify the source of the error within the repository structure.\n3. Explain the error concisely in natural language.\n4. Provide specific, actionable suggestions for resolving the error.\n5. Format your response as a JSON object with the exact structure specified below."
22:         },
23:         {
24:           "role": "system",
25:           "content": "Your response MUST be a valid JSON object with this exact structure:\n{\n  \"where\": {\n    \"repository_path\": \"<absolute path to repository>\",\n    \"file_name\": \"<name of file containing error>\",\n    \"line_number\": \"<line number where error occurred>\"\n  },\n  \"what\": {\n    \"error_type\": \"<specific Python error type>\",\n    \"description\": \"<concise explanation of error>\"\n  },\n  \"how\": {\n    \"error_origination\": \"<line number where error originated>\",\n    \"suggested_code_solution\": \"<code snippet to fix the error>\"\n  }\n}"
26:         },
27:         {
28:           "role": "system",
29:           "content": "Constraints:\n- Provide ONLY the JSON object as your response. Do not include any other text.\n- Ensure all JSON keys are exactly as specified.\n- The 'suggested_code_solution' should be a valid Python code snippet without explanation.\n- If multiple errors exist, focus on the most critical one that likely caused the others.\n- Do not use placeholders in your response. Provide specific, contextual information based on the given error. Only fix the line from the line number given that is causing the error."
30:         },
31:         {
32:           "role": "user",
33:           "content": f"Context: {context}\n\nTraceback message: {traceback_message}\n\nOriginal error message: {original_error_information}"
34:         }
35:       ],
36:     model="llama3-70b-8192",
37:     response_format={"type": "json_object"}
38:   )
39:   return chat_completion.choices[0].message.content
40: 
41: if __name__ == "__main__":
42:    print(process(["test.py"], """File "/Users/vinh/Documents/calhacks24/test.py", line 2
43:           print(hello
44:                ^
45:       SyntaxError: '(' was never closed"""))

================
File: repomixer/context_collector.py
================
  1: import os
  2: import re
  3: from pathlib import Path
  4: from typing import List, Set, Dict, Optional
  5: 
  6: 
  7: class ContextCollector:
  8:     def __init__(self, project_root: str):
  9:         self.project_root = Path(project_root)
 10:         self.file_cache: Dict[str, str] = {}  # Cache file contents
 11:         self.supported_extensions = ['py', 'js', 'jsx', 'ts', 'tsx', 'java', 'cpp', 'h', 'rs', 'go']
 12: 
 13:     def collect_context(self, query: str, starting_file: Optional[str] = None) -> List[str]:
 14:         """
 15:         Collect relevant files based on:
 16:         1. Direct file mentions in query
 17:         2. Keywords/topics from query
 18:         3. If starting_file provided, related files to it
 19:         4. Project structure proximity
 20:         """
 21:         relevant_files = set()
 22: 
 23:         # Strategy 1: Direct file mentions
 24:         mentioned_files = self._find_file_mentions(query)
 25:         relevant_files.update(mentioned_files)
 26: 
 27:         # Strategy 2: Keyword-based search
 28:         keyword_files = self._find_files_by_keywords(query)
 29:         relevant_files.update(keyword_files)
 30: 
 31:         # Strategy 3: Starting file context
 32:         if starting_file:
 33:             related_files = self._find_related_files(starting_file)
 34:             relevant_files.update(related_files)
 35: 
 36:         # Strategy 4: Project structure proximity
 37:         proximity_files = self._find_proximity_files(relevant_files)
 38:         relevant_files.update(proximity_files)
 39: 
 40:         return list(relevant_files)
 41: 
 42:     def _find_file_mentions(self, text: str) -> Set[str]:
 43:         """Find directly mentioned files in text"""
 44:         files = set()
 45:         # Regex pattern to match filenames with supported extensions
 46:         file_pattern = re.compile(r'\b[\w\-./\\]+\.(?:' + '|'.join(self.supported_extensions) + r')\b')
 47:         matches = file_pattern.findall(text)
 48:         for match in matches:
 49:             file_path = self.project_root / Path(match)
 50:             if file_path.exists():
 51:                 files.add(str(file_path.resolve()))
 52:         return files
 53: 
 54:     def _find_files_by_keywords(self, query: str) -> Set[str]:
 55:         """Find files that contain keywords from the query"""
 56:         keywords = self._extract_keywords(query)
 57:         if not keywords:
 58:             return set()
 59: 
 60:         matching_files = set()
 61:         for file_path in self._iter_project_files():
 62:             content = self._read_file(file_path)
 63:             if content:
 64:                 if any(keyword.lower() in content.lower() for keyword in keywords):
 65:                     matching_files.add(str(file_path.resolve()))
 66:         return matching_files
 67: 
 68:     def _extract_keywords(self, text: str) -> Set[str]:
 69:         """Extract keywords from the query by splitting on non-word characters"""
 70:         # Simple keyword extraction; can be enhanced with NLP techniques
 71:         keywords = set(re.findall(r'\b\w+\b', text))
 72:         return keywords
 73: 
 74:     def _find_related_files(self, starting_file: str) -> Set[str]:
 75:         """Find related files based on the starting file's directory"""
 76:         related = set()
 77:         start_path = self.project_root / Path(starting_file)
 78:         if not start_path.exists():
 79:             print(f"Starting file {start_path} does not exist.")
 80:             return related
 81: 
 82:         if start_path.is_file():
 83:             dir_path = start_path.parent
 84:         else:
 85:             dir_path = start_path
 86: 
 87:         # Include all supported files in the same directory
 88:         for ext in self.supported_extensions:
 89:             for file in dir_path.glob(f'*.{ext}'):
 90:                 related.add(str(file.resolve()))
 91:         return related
 92: 
 93:     def _find_proximity_files(self, current_files: Set[str]) -> Set[str]:
 94:         """
 95:         Find files that are in the same or adjacent directories
 96:         as the current relevant files.
 97:         """
 98:         proximity = set()
 99:         for file in current_files:
100:             file_path = Path(file)
101:             parent_dir = file_path.parent
102:             # Include files from the parent directory
103:             for ext in self.supported_extensions:
104:                 for f in parent_dir.glob(f'*.{ext}'):
105:                     proximity.add(str(f.resolve()))
106:             # Optionally, include files from child directories
107:             for ext in self.supported_extensions:
108:                 for f in file_path.rglob(f'*.{ext}'):
109:                     proximity.add(str(f.resolve()))
110:         return proximity
111: 
112:     def _iter_project_files(self) -> List[Path]:
113:         """Iterate through all supported files in the project"""
114:         files = []
115:         for ext in self.supported_extensions:
116:             files.extend(self.project_root.rglob(f'*.{ext}'))
117:         return files
118: 
119:     def _read_file(self, file_path: Path) -> str:
120:         """Read and cache the content of a file"""
121:         path_str = str(file_path.resolve())
122:         if path_str in self.file_cache:
123:             return self.file_cache[path_str]
124:         try:
125:             with open(file_path, 'r', encoding='utf-8') as f:
126:                 content = f.read()
127:             self.file_cache[path_str] = content
128:             return content
129:         except (UnicodeDecodeError, FileNotFoundError, PermissionError) as e:
130:             print(f"Failed to read {file_path}: {e}")
131:             return ""

================
File: repomixer/stack_trace_parser.py
================
 1: import os
 2: import re
 3: from typing import List, Set, Optional
 4: 
 5: class StackTraceParser:
 6:     def __init__(self, project_root: Optional[str] = None):
 7:         self.project_root = project_root or os.getcwd()
 8:         self.file_pattern = re.compile(r'(?:'
 9:                     r'File "([^"]+)"|'  # Python
10:                     r'at\s+(?:.*?\()?([^\s:()]+?\.[a-zA-Z]+)(?::\d+)?(?:\))?|'  # JS/Java
11:                     r'\b(/[^:]+\.[a-zA-Z]+)|'  # Absolute paths
12:                     r'\b(\S+\.[a-zA-Z]+)\b'  # Any file with extension
13:                     r')'
14:             )
15:         # Common system paths to exclude
16:         self.exclude_patterns = [
17:             r'node_modules',
18:             r'site-packages',
19:             r'internal/modules',
20:             r'lib/python[\d.]+',
21:             r'java/lang',
22:         ]
23:     def normalize_path(self, path: str) -> str:
24:             """Convert relative paths to absolute and normalize slashes"""
25:             if not os.path.isabs(path):
26:                 path = os.path.join(self.project_root, path)
27:             return os.path.normpath(path)
28: 
29:     def should_include_file(self, file_path: str) -> bool:
30:         """Check if file should be included in results"""
31:         # Exclude system files
32:         for pattern in self.exclude_patterns:
33:             if re.search(pattern, file_path):
34:                 return False
35: 
36:         # Check if file exists
37:         normalized_path = self.normalize_path(file_path)
38:         return os.path.exists(normalized_path)
39: 
40:     def extract_files(self, error_trace: str) -> List[str]:
41:         """Extract file paths from error trace"""
42:         files: Set[str] = set()
43: 
44:         matches = self.file_pattern.finditer(error_trace)
45:         for match in matches:
46:             # Get the first non-None group
47:             file_path = next((
48:                 group for group in match.groups()
49:                 if group is not None
50:             ), None)
51: 
52:             if file_path and self.should_include_file(file_path):
53:                 normalized_path = self.normalize_path(file_path)
54:                 files.add(normalized_path)
55: 
56:         return list(files)
57: 
58:     def get_related_files(self, files: List[str]) -> List[str]:
59:         """Get related files from the same directories"""
60:         related: Set[str] = set()
61: 
62:         for file_path in files:
63:             dir_path = os.path.dirname(file_path)
64:             if os.path.exists(dir_path):
65:                 for f in os.listdir(dir_path):
66:                     if f.endswith(('.py', '.js', '.java', '.ts', '.rs','.kt','.scala','.swift','.r','.R', '.pl', '.pm', '.hs', '.lua', '.c', '.cpp', '.jsx', '.tsx', )):  # add more extensions as needed
67:                         full_path = os.path.join(dir_path, f)
68:                         related.add(full_path)
69: 
70:         return list(related)

================
File: shelly.egg-info/dependency_links.txt
================
1: 

================
File: shelly.egg-info/entry_points.txt
================
1: [console_scripts]
2: shelly = shelly:cli

================
File: shelly.egg-info/PKG-INFO
================
1: Metadata-Version: 2.1
2: Name: shelly
3: Version: 0.1

================
File: shelly.egg-info/requires.txt
================
1: Click

================
File: shelly.egg-info/SOURCES.txt
================
 1: README.md
 2: setup.py
 3: agents/__init__.py
 4: agents/agents.py
 5: agents/file_writer_agent.py
 6: agents/interaction.py
 7: agents/splatter.py
 8: agents/zapper.py
 9: cli/__init__.py
10: cli/child_terminal.py
11: cli/cli.py
12: cli/listener.py
13: cli/process_monitor.py
14: shelly.egg-info/PKG-INFO
15: shelly.egg-info/SOURCES.txt
16: shelly.egg-info/dependency_links.txt
17: shelly.egg-info/entry_points.txt
18: shelly.egg-info/requires.txt
19: shelly.egg-info/top_level.txt
20: test/test.py
21: utils/__init__.py
22: utils/utils.py

================
File: shelly.egg-info/top_level.txt
================
1: agents
2: cli
3: shelly
4: utils

================
File: terminalout/terminal.py
================
 1: import json
 2: from prompt_toolkit.formatted_text import to_formatted_text, HTML
 3: from prompt_toolkit import print_formatted_text, HTML
 4: from prompt_toolkit.shortcuts import prompt, PromptSession
 5: from prompt_toolkit.key_binding import KeyBindings
 6: from prompt_toolkit.styles import Style
 7: from agents.file_writer_agent import file_writer, ErrorCorrectionRequest, FileWriteResponse 
 8: 
 9: # Initialize the file_writer agent
10: file_writer_agent = file_writer
11: 
12: def terminalstep1(json_object):
13:     data = json.loads(json_object)
14:     #Print where and what
15:     print_formatted_text(HTML("🔎 <u><b><gray>Details about <red>error</red></gray></b></u>"))
16:     print_formatted_text(HTML(f"✅ We found the first instance of the <red><b>error</b></red> at <b><magenta>line {data['where']['line_number']}</magenta></b>."))
17:     print_formatted_text(HTML(f"✅ The owner of the <b><red>error</red></b>: <b><magenta>{data['where']['file_name']}</magenta></b>."))
18:     print_formatted_text(HTML(f"✅ The type of the <b><red>error</red></b>: <b><magenta>{data['what']['error_type']}</magenta></b>."))
19:     print_formatted_text(HTML(f"✅ Isolated <red><b>error</b></red> message: <b><cyan>{data['what']['description']}</cyan></b>"))
20:     #user can select if they wanna see the solution
21: 
22:     current_index = 0  # 0 for YES, 1 for NO
23:     kb = KeyBindings()
24:     options = ['y', 'n']
25: 
26:     @kb.add('left')  # Select 'YES'
27:     def select_yes(event):
28:         nonlocal current_index
29:         current_index = 0  # Select 'y'
30:         update_display(event.app)
31: 
32:     @kb.add('right')  # Select 'NO'
33:     def select_no(event):
34:         nonlocal current_index
35:         current_index = 1  # Select 'n'
36:         update_display(event.app)
37: 
38:     @kb.add('enter')  # Confirm selection
39:     def confirm_selection(event):
40:         event.app.exit()
41: 
42:     def format_bold(text):
43:         return f"<u><yellow>{text}</yellow></u>"
44: 
45:     def format_regular(text):
46:         return f"<white>{text}</white>"
47: 
48:     def update_display(app):
49:         """Update the displayed selection."""
50:         yes_text = format_bold("Yes") if current_index == 0 else format_regular("Yes")
51:         no_text = format_bold("No") if current_index == 1 else format_regular("No")
52:         display_string = (
53:             f"\rDo you want to see the solution?: "
54:             f"YES/no" if current_index == 0 else
55:             f""
56:             f"\rDo you want to see the solution and apply changes?: "
57:             f"yes/NO" if current_index == 1 else
58:             f""
59:         )
60:         app.output.write(display_string)
61:         app.output.flush()
62: 
63:         # Clear the line and print the new options with proper formatting
64:         app.output.write("\r")  # Carries the cursor back to the start of the line
65:         print_formatted_text(HTML(f"See suggested change? <gray>...</gray> {yes_text} / {no_text}   "), end='')  # Ensure no new line is printed
66: 
67:     # Initial display update
68:     session = PromptSession(key_bindings=kb)
69:     update_display(session.app)  # Initial display
70:     session.prompt("")  # Start prompt
71: 
72:     if options[current_index] == 'y':
73:         print_formatted_text(HTML("<b><ansigreen>How to fix error:</ansigreen></b>"), data['how'])
74:         return True, data
75:     else:
76:         print_formatted_text(HTML("<b><ansigreen>No changes will be applied.</ansigreen></b>"))
77:         return False, None

================
File: test/test-nextjs-project/src/app/globals.css
================
 1: @tailwind base;
 2: @tailwind components;
 3: @tailwind utilities;
 4: 
 5: :root {
 6:   --background: #ffffff;
 7:   --foreground: #171717;
 8: }
 9: 
10: @media (prefers-color-scheme: dark) {
11:   :root {
12:     --background: #0a0a0a;
13:     --foreground: #ededed;
14:   }
15: }
16: 
17: body {
18:   color: var(--foreground);
19:   background: var(--background);
20:   font-family: Arial, Helvetica, sans-serif;
21: }
22: 
23: @layer utilities {
24:   .text-balance {
25:     text-wrap: balance;
26:   }
27: }

================
File: test/test-nextjs-project/src/app/layout.tsx
================
 1: import type { Metadata } from "next";
 2: import localFont from "next/font/local";
 3: import "./globals.css";
 4: 
 5: const geistSans = localFont({
 6:   src: "./fonts/GeistVF.woff",
 7:   variable: "--font-geist-sans",
 8:   weight: "100 900",
 9: });
10: const geistMono = localFont({
11:   src: "./fonts/GeistMonoVF.woff",
12:   variable: "--font-geist-mono",
13:   weight: "100 900",
14: });
15: 
16: export const metadata: Metadata = {
17:   title: "Create Next App",
18:   description: "Generated by create next app",
19: };
20: 
21: export default function RootLayout({
22:   children,
23: }: Readonly<{
24:   children: React.ReactNode;
25: }>) {
26:   return (
27:     <html lang="en">
28:       <body
29:         className={`${geistSans.variable} ${geistMono.variable} antialiased`}
30:       >
31:         {children}
32:       </body>
33:     </html>
34:   );
35: }

================
File: test/test-nextjs-project/src/app/page.tsx
================
 1: // src/app/page.tsx
 2: "use client"
 3: import { useState } from 'react';
 4: 
 5: export default function Home() {
 6:   const [result, setResult] = useState('');
 7: 
 8:   const handleSubmit = async (event: React.FormEvent<HTMLFormElement>) => {
 9:     event.preventDefault();
10:     const formData = new FormData(event.currentTarget);
11:     const endpoint = formData.get('endpoint') as string;
12: 
13:     try {
14:       const response = await fetch(`http://localhost:8000${endpoint}`);
15:       const data = await response.json();
16:       setResult(JSON.stringify(data, null, 2));
17:     } catch (error) {
18:       setResult(`Error: ${error}`);
19:     }
20:   };
21: 
22:   return (
23:     <div className="container mx-auto p-4">
24:       <h1 className="text-2xl font-bold mb-4">FastAPI Bug Tester</h1>
25:       <form onSubmit={handleSubmit} className="mb-4">
26:         <select name="endpoint" className="mr-2 p-2 border rounded">
27:           <option value="/users">Get Users</option>
28:           <option value="/items">Get Items</option>
29:           <option value="/process">Process Data</option>
30:         </select>
31:         <button type="submit" className="bg-blue-500 text-white p-2 rounded">
32:           Send Request
33:         </button>
34:       </form>
35:       <pre className="bg-gray-100 p-4 rounded">{result}</pre>
36:     </div>
37:   );
38: }

================
File: test/test-nextjs-project/.eslintrc.json
================
1: {
2:   "extends": ["next/core-web-vitals", "next/typescript"]
3: }

================
File: test/test-nextjs-project/.gitignore
================
 1: # See https://help.github.com/articles/ignoring-files/ for more about ignoring files.
 2: 
 3: # dependencies
 4: /node_modules
 5: /.pnp
 6: .pnp.js
 7: .yarn/install-state.gz
 8: 
 9: # testing
10: /coverage
11: 
12: # next.js
13: /.next/
14: /out/
15: 
16: # production
17: /build
18: 
19: # misc
20: .DS_Store
21: *.pem
22: 
23: # debug
24: npm-debug.log*
25: yarn-debug.log*
26: yarn-error.log*
27: 
28: # local env files
29: .env*.local
30: 
31: # vercel
32: .vercel
33: 
34: # typescript
35: *.tsbuildinfo
36: next-env.d.ts

================
File: test/test-nextjs-project/next.config.mjs
================
1: /** @type {import('next').NextConfig} */
2: const nextConfig = {};
3: 
4: export default nextConfig;

================
File: test/test-nextjs-project/package.json
================
 1: {
 2:   "name": "test-nextjs-project",
 3:   "version": "0.1.0",
 4:   "private": true,
 5:   "scripts": {
 6:     "dev": "next dev",
 7:     "build": "next build",
 8:     "start": "next start",
 9:     "lint": "next lint"
10:   },
11:   "dependencies": {
12:     "next": "14.2.15",
13:     "react": "^18.3.1",
14:     "react-dom": "^18"
15:   },
16:   "devDependencies": {
17:     "@types/node": "^20",
18:     "@types/react": "^18",
19:     "@types/react-dom": "^18",
20:     "eslint": "^8",
21:     "eslint-config-next": "14.2.15",
22:     "postcss": "^8",
23:     "tailwindcss": "^3.4.1",
24:     "typescript": "^5"
25:   }
26: }

================
File: test/test-nextjs-project/postcss.config.mjs
================
1: /** @type {import('postcss-load-config').Config} */
2: const config = {
3:   plugins: {
4:     tailwindcss: {},
5:   },
6: };
7: 
8: export default config;

================
File: test/test-nextjs-project/README.md
================
 1: This is a [Next.js](https://nextjs.org) project bootstrapped with [`create-next-app`](https://nextjs.org/docs/app/api-reference/cli/create-next-app).
 2: 
 3: ## Getting Started
 4: 
 5: First, run the development server:
 6: 
 7: ```bash
 8: npm run dev
 9: # or
10: yarn dev
11: # or
12: pnpm dev
13: # or
14: bun dev
15: ```
16: 
17: Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.
18: 
19: You can start editing the page by modifying `app/page.tsx`. The page auto-updates as you edit the file.
20: 
21: This project uses [`next/font`](https://nextjs.org/docs/app/building-your-application/optimizing/fonts) to automatically optimize and load [Geist](https://vercel.com/font), a new font family for Vercel.
22: 
23: ## Learn More
24: 
25: To learn more about Next.js, take a look at the following resources:
26: 
27: - [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.
28: - [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.
29: 
30: You can check out [the Next.js GitHub repository](https://github.com/vercel/next.js) - your feedback and contributions are welcome!
31: 
32: ## Deploy on Vercel
33: 
34: The easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.
35: 
36: Check out our [Next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) for more details.

================
File: test/test-nextjs-project/tailwind.config.ts
================
 1: import type { Config } from "tailwindcss";
 2: 
 3: const config: Config = {
 4:   content: [
 5:     "./src/pages/**/*.{js,ts,jsx,tsx,mdx}",
 6:     "./src/components/**/*.{js,ts,jsx,tsx,mdx}",
 7:     "./src/app/**/*.{js,ts,jsx,tsx,mdx}",
 8:   ],
 9:   theme: {
10:     extend: {
11:       colors: {
12:         background: "var(--background)",
13:         foreground: "var(--foreground)",
14:       },
15:     },
16:   },
17:   plugins: [],
18: };
19: export default config;

================
File: test/test-nextjs-project/tsconfig.json
================
 1: {
 2:   "compilerOptions": {
 3:     "lib": ["dom", "dom.iterable", "esnext"],
 4:     "allowJs": true,
 5:     "skipLibCheck": true,
 6:     "strict": true,
 7:     "noEmit": true,
 8:     "esModuleInterop": true,
 9:     "module": "esnext",
10:     "moduleResolution": "bundler",
11:     "resolveJsonModule": true,
12:     "isolatedModules": true,
13:     "jsx": "preserve",
14:     "incremental": true,
15:     "plugins": [
16:       {
17:         "name": "next"
18:       }
19:     ],
20:     "paths": {
21:       "@/*": ["./src/*"]
22:     }
23:   },
24:   "include": ["next-env.d.ts", "**/*.ts", "**/*.tsx", ".next/types/**/*.ts"],
25:   "exclude": ["node_modules"]
26: }

================
File: test/test-react-app/public/index.html
================
 1: <!DOCTYPE html>
 2: <html lang="en">
 3:   <head>
 4:     <meta charset="utf-8" />
 5:     <link rel="icon" href="%PUBLIC_URL%/favicon.ico" />
 6:     <meta name="viewport" content="width=device-width, initial-scale=1" />
 7:     <meta name="theme-color" content="#000000" />
 8:     <meta
 9:       name="description"
10:       content="Web site created using create-react-app"
11:     />
12:     <link rel="apple-touch-icon" href="%PUBLIC_URL%/logo192.png" />
13:     <!--
14:       manifest.json provides metadata used when your web app is installed on a
15:       user's mobile device or desktop. See https://developers.google.com/web/fundamentals/web-app-manifest/
16:     -->
17:     <link rel="manifest" href="%PUBLIC_URL%/manifest.json" />
18:     <!--
19:       Notice the use of %PUBLIC_URL% in the tags above.
20:       It will be replaced with the URL of the `public` folder during the build.
21:       Only files inside the `public` folder can be referenced from the HTML.
22: 
23:       Unlike "/favicon.ico" or "favicon.ico", "%PUBLIC_URL%/favicon.ico" will
24:       work correctly both with client-side routing and a non-root public URL.
25:       Learn how to configure a non-root public URL by running `npm run build`.
26:     -->
27:     <title>React App</title>
28:   </head>
29:   <body>
30:     <noscript>You need to enable JavaScript to run this app.</noscript>
31:     <div id="root"></div>
32:     <!--
33:       This HTML file is a template.
34:       If you open it directly in the browser, you will see an empty page.
35: 
36:       You can add webfonts, meta tags, or analytics to this file.
37:       The build step will place the bundled scripts into the <body> tag.
38: 
39:       To begin the development, run `npm start` or `yarn start`.
40:       To create a production bundle, use `npm run build` or `yarn build`.
41:     -->
42:   </body>
43: </html>

================
File: test/test-react-app/public/manifest.json
================
 1: {
 2:   "short_name": "React App",
 3:   "name": "Create React App Sample",
 4:   "icons": [
 5:     {
 6:       "src": "favicon.ico",
 7:       "sizes": "64x64 32x32 24x24 16x16",
 8:       "type": "image/x-icon"
 9:     },
10:     {
11:       "src": "logo192.png",
12:       "type": "image/png",
13:       "sizes": "192x192"
14:     },
15:     {
16:       "src": "logo512.png",
17:       "type": "image/png",
18:       "sizes": "512x512"
19:     }
20:   ],
21:   "start_url": ".",
22:   "display": "standalone",
23:   "theme_color": "#000000",
24:   "background_color": "#ffffff"
25: }

================
File: test/test-react-app/public/robots.txt
================
1: # https://www.robotstxt.org/robotstxt.html
2: User-agent: *
3: Disallow:

================
File: test/test-react-app/src/App.css
================
 1: .App {
 2:   text-align: center;
 3: }
 4: 
 5: .App-logo {
 6:   height: 40vmin;
 7:   pointer-events: none;
 8: }
 9: 
10: @media (prefers-reduced-motion: no-preference) {
11:   .App-logo {
12:     animation: App-logo-spin infinite 20s linear;
13:   }
14: }
15: 
16: .App-header {
17:   background-color: #282c34;
18:   min-height: 100vh;
19:   display: flex;
20:   flex-direction: column;
21:   align-items: center;
22:   justify-content: center;
23:   font-size: calc(10px + 2vmin);
24:   color: white;
25: }
26: 
27: .App-link {
28:   color: #61dafb;
29: }
30: 
31: @keyframes App-logo-spin {
32:   from {
33:     transform: rotate(0deg);
34:   }
35:   to {
36:     transform: rotate(360deg);
37:   }
38: }

================
File: test/test-react-app/src/App.js
================
 1: import logo from './logo.svg';
 2: import './App.css';
 3: 
 4: function App() {
 5:   return (
 6:     <div className="App">
 7:       <header className="App-header">
 8:         <img src={logo} className="App-logo" alt="logo"
 9:         <p>
10:           Edit <code>src/App.js</code> and save to reload.
11:         </p>
12:         <a
13:           className="App-link"
14:           href="https://reactjs.org"
15:           target="_blank"
16:           rel="noopener noreferrer"
17:         >
18:           Learn React
19:         </a>
20:       </header>
21:     </div>
22:   );
23: }
24: 
25: export default App;

================
File: test/test-react-app/src/App.test.js
================
1: import { render, screen } from '@testing-library/react';
2: import App from './App';
3: 
4: test('renders learn react link', () => {
5:   render(<App />);
6:   const linkElement = screen.getByText(/learn react/i);
7:   expect(linkElement).toBeInTheDocument();
8: });

================
File: test/test-react-app/src/index.css
================
 1: body {
 2:   margin: 0;
 3:   font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', 'Oxygen',
 4:     'Ubuntu', 'Cantarell', 'Fira Sans', 'Droid Sans', 'Helvetica Neue',
 5:     sans-serif;
 6:   -webkit-font-smoothing: antialiased;
 7:   -moz-osx-font-smoothing: grayscale;
 8: }
 9: 
10: code {
11:   font-family: source-code-pro, Menlo, Monaco, Consolas, 'Courier New',
12:     monospace;
13: }

================
File: test/test-react-app/src/index.js
================
 1: import React from 'react';
 2: import ReactDOM from 'react-dom/client';
 3: import './index.css';
 4: import App from './App';
 5: import reportWebVitals from './reportWebVitals';
 6: 
 7: const root = ReactDOM.createRoot(document.getElementById('root'));
 8: root.render(
 9:   <React.StrictMode>
10:     <App />
11:   </React.StrictMode>
12: );
13: 
14: // If you want to start measuring performance in your app, pass a function
15: // to log results (for example: reportWebVitals(console.log))
16: // or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals
17: reportWebVitals();

================
File: test/test-react-app/src/logo.svg
================
1: <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 841.9 595.3"><g fill="#61DAFB"><path d="M666.3 296.5c0-32.5-40.7-63.3-103.1-82.4 14.4-63.6 8-114.2-20.2-130.4-6.5-3.8-14.1-5.6-22.4-5.6v22.3c4.6 0 8.3.9 11.4 2.6 13.6 7.8 19.5 37.5 14.9 75.7-1.1 9.4-2.9 19.3-5.1 29.4-19.6-4.8-41-8.5-63.5-10.9-13.5-18.5-27.5-35.3-41.6-50 32.6-30.3 63.2-46.9 84-46.9V78c-27.5 0-63.5 19.6-99.9 53.6-36.4-33.8-72.4-53.2-99.9-53.2v22.3c20.7 0 51.4 16.5 84 46.6-14 14.7-28 31.4-41.3 49.9-22.6 2.4-44 6.1-63.6 11-2.3-10-4-19.7-5.2-29-4.7-38.2 1.1-67.9 14.6-75.8 3-1.8 6.9-2.6 11.5-2.6V78.5c-8.4 0-16 1.8-22.6 5.6-28.1 16.2-34.4 66.7-19.9 130.1-62.2 19.2-102.7 49.9-102.7 82.3 0 32.5 40.7 63.3 103.1 82.4-14.4 63.6-8 114.2 20.2 130.4 6.5 3.8 14.1 5.6 22.5 5.6 27.5 0 63.5-19.6 99.9-53.6 36.4 33.8 72.4 53.2 99.9 53.2 8.4 0 16-1.8 22.6-5.6 28.1-16.2 34.4-66.7 19.9-130.1 62-19.1 102.5-49.9 102.5-82.3zm-130.2-66.7c-3.7 12.9-8.3 26.2-13.5 39.5-4.1-8-8.4-16-13.1-24-4.6-8-9.5-15.8-14.4-23.4 14.2 2.1 27.9 4.7 41 7.9zm-45.8 106.5c-7.8 13.5-15.8 26.3-24.1 38.2-14.9 1.3-30 2-45.2 2-15.1 0-30.2-.7-45-1.9-8.3-11.9-16.4-24.6-24.2-38-7.6-13.1-14.5-26.4-20.8-39.8 6.2-13.4 13.2-26.8 20.7-39.9 7.8-13.5 15.8-26.3 24.1-38.2 14.9-1.3 30-2 45.2-2 15.1 0 30.2.7 45 1.9 8.3 11.9 16.4 24.6 24.2 38 7.6 13.1 14.5 26.4 20.8 39.8-6.3 13.4-13.2 26.8-20.7 39.9zm32.3-13c5.4 13.4 10 26.8 13.8 39.8-13.1 3.2-26.9 5.9-41.2 8 4.9-7.7 9.8-15.6 14.4-23.7 4.6-8 8.9-16.1 13-24.1zM421.2 430c-9.3-9.6-18.6-20.3-27.8-32 9 .4 18.2.7 27.5.7 9.4 0 18.7-.2 27.8-.7-9 11.7-18.3 22.4-27.5 32zm-74.4-58.9c-14.2-2.1-27.9-4.7-41-7.9 3.7-12.9 8.3-26.2 13.5-39.5 4.1 8 8.4 16 13.1 24 4.7 8 9.5 15.8 14.4 23.4zM420.7 163c9.3 9.6 18.6 20.3 27.8 32-9-.4-18.2-.7-27.5-.7-9.4 0-18.7.2-27.8.7 9-11.7 18.3-22.4 27.5-32zm-74 58.9c-4.9 7.7-9.8 15.6-14.4 23.7-4.6 8-8.9 16-13 24-5.4-13.4-10-26.8-13.8-39.8 13.1-3.1 26.9-5.8 41.2-7.9zm-90.5 125.2c-35.4-15.1-58.3-34.9-58.3-50.6 0-15.7 22.9-35.6 58.3-50.6 8.6-3.7 18-7 27.7-10.1 5.7 19.6 13.2 40 22.5 60.9-9.2 20.8-16.6 41.1-22.2 60.6-9.9-3.1-19.3-6.5-28-10.2zM310 490c-13.6-7.8-19.5-37.5-14.9-75.7 1.1-9.4 2.9-19.3 5.1-29.4 19.6 4.8 41 8.5 63.5 10.9 13.5 18.5 27.5 35.3 41.6 50-32.6 30.3-63.2 46.9-84 46.9-4.5-.1-8.3-1-11.3-2.7zm237.2-76.2c4.7 38.2-1.1 67.9-14.6 75.8-3 1.8-6.9 2.6-11.5 2.6-20.7 0-51.4-16.5-84-46.6 14-14.7 28-31.4 41.3-49.9 22.6-2.4 44-6.1 63.6-11 2.3 10.1 4.1 19.8 5.2 29.1zm38.5-66.7c-8.6 3.7-18 7-27.7 10.1-5.7-19.6-13.2-40-22.5-60.9 9.2-20.8 16.6-41.1 22.2-60.6 9.9 3.1 19.3 6.5 28.1 10.2 35.4 15.1 58.3 34.9 58.3 50.6-.1 15.7-23 35.6-58.4 50.6zM320.8 78.4z"/><circle cx="420.9" cy="296.5" r="45.7"/><path d="M520.5 78.1z"/></g></svg>

================
File: test/test-react-app/src/reportWebVitals.js
================
 1: const reportWebVitals = onPerfEntry => {
 2:   if (onPerfEntry && onPerfEntry instanceof Function) {
 3:     import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {
 4:       getCLS(onPerfEntry);
 5:       getFID(onPerfEntry);
 6:       getFCP(onPerfEntry);
 7:       getLCP(onPerfEntry);
 8:       getTTFB(onPerfEntry);
 9:     });
10:   }
11: };
12: 
13: export default reportWebVitals;

================
File: test/test-react-app/src/setupTests.js
================
1: // jest-dom adds custom jest matchers for asserting on DOM nodes.
2: // allows you to do things like:
3: // expect(element).toHaveTextContent(/react/i)
4: // learn more: https://github.com/testing-library/jest-dom
5: import '@testing-library/jest-dom';

================
File: test/test-react-app/.gitignore
================
 1: # See https://help.github.com/articles/ignoring-files/ for more about ignoring files.
 2: 
 3: # dependencies
 4: /node_modules
 5: /.pnp
 6: .pnp.js
 7: 
 8: # testing
 9: /coverage
10: 
11: # production
12: /build
13: 
14: # misc
15: .DS_Store
16: .env.local
17: .env.development.local
18: .env.test.local
19: .env.production.local
20: 
21: npm-debug.log*
22: yarn-debug.log*
23: yarn-error.log*

================
File: test/test-react-app/package.json
================
 1: {
 2:   "name": "test-react-app",
 3:   "version": "0.1.0",
 4:   "private": true,
 5:   "dependencies": {
 6:     "@testing-library/jest-dom": "^5.17.0",
 7:     "@testing-library/react": "^13.4.0",
 8:     "@testing-library/user-event": "^13.5.0",
 9:     "react": "^18.3.1",
10:     "react-dom": "^18.3.1",
11:     "react-scripts": "5.0.1",
12:     "web-vitals": "^2.1.4"
13:   },
14:   "scripts": {
15:     "start": "react-scripts start",
16:     "build": "react-scripts build",
17:     "test": "react-scripts test",
18:     "eject": "react-scripts eject"
19:   },
20:   "eslintConfig": {
21:     "extends": [
22:       "react-app",
23:       "react-app/jest"
24:     ]
25:   },
26:   "browserslist": {
27:     "production": [
28:       ">0.2%",
29:       "not dead",
30:       "not op_mini all"
31:     ],
32:     "development": [
33:       "last 1 chrome version",
34:       "last 1 firefox version",
35:       "last 1 safari version"
36:     ]
37:   }
38: }

================
File: test/test-react-app/README.md
================
 1: # Getting Started with Create React App
 2: 
 3: This project was bootstrapped with [Create React App](https://github.com/facebook/create-react-app).
 4: 
 5: ## Available Scripts
 6: 
 7: In the project directory, you can run:
 8: 
 9: ### `npm start`
10: 
11: Runs the app in the development mode.\
12: Open [http://localhost:3000](http://localhost:3000) to view it in your browser.
13: 
14: The page will reload when you make changes.\
15: You may also see any lint errors in the console.
16: 
17: ### `npm test`
18: 
19: Launches the test runner in the interactive watch mode.\
20: See the section about [running tests](https://facebook.github.io/create-react-app/docs/running-tests) for more information.
21: 
22: ### `npm run build`
23: 
24: Builds the app for production to the `build` folder.\
25: It correctly bundles React in production mode and optimizes the build for the best performance.
26: 
27: The build is minified and the filenames include the hashes.\
28: Your app is ready to be deployed!
29: 
30: See the section about [deployment](https://facebook.github.io/create-react-app/docs/deployment) for more information.
31: 
32: ### `npm run eject`
33: 
34: **Note: this is a one-way operation. Once you `eject`, you can't go back!**
35: 
36: If you aren't satisfied with the build tool and configuration choices, you can `eject` at any time. This command will remove the single build dependency from your project.
37: 
38: Instead, it will copy all the configuration files and the transitive dependencies (webpack, Babel, ESLint, etc) right into your project so you have full control over them. All of the commands except `eject` will still work, but they will point to the copied scripts so you can tweak them. At this point you're on your own.
39: 
40: You don't have to ever use `eject`. The curated feature set is suitable for small and middle deployments, and you shouldn't feel obligated to use this feature. However we understand that this tool wouldn't be useful if you couldn't customize it when you are ready for it.
41: 
42: ## Learn More
43: 
44: You can learn more in the [Create React App documentation](https://facebook.github.io/create-react-app/docs/getting-started).
45: 
46: To learn React, check out the [React documentation](https://reactjs.org/).
47: 
48: ### Code Splitting
49: 
50: This section has moved here: [https://facebook.github.io/create-react-app/docs/code-splitting](https://facebook.github.io/create-react-app/docs/code-splitting)
51: 
52: ### Analyzing the Bundle Size
53: 
54: This section has moved here: [https://facebook.github.io/create-react-app/docs/analyzing-the-bundle-size](https://facebook.github.io/create-react-app/docs/analyzing-the-bundle-size)
55: 
56: ### Making a Progressive Web App
57: 
58: This section has moved here: [https://facebook.github.io/create-react-app/docs/making-a-progressive-web-app](https://facebook.github.io/create-react-app/docs/making-a-progressive-web-app)
59: 
60: ### Advanced Configuration
61: 
62: This section has moved here: [https://facebook.github.io/create-react-app/docs/advanced-configuration](https://facebook.github.io/create-react-app/docs/advanced-configuration)
63: 
64: ### Deployment
65: 
66: This section has moved here: [https://facebook.github.io/create-react-app/docs/deployment](https://facebook.github.io/create-react-app/docs/deployment)
67: 
68: ### `npm run build` fails to minify
69: 
70: This section has moved here: [https://facebook.github.io/create-react-app/docs/troubleshooting#npm-run-build-fails-to-minify](https://facebook.github.io/create-react-app/docs/troubleshooting#npm-run-build-fails-to-minify)

================
File: test/FaultyJava.java
================
 1: public class FaultyJava {
 2:     public static void main(String[] args) {
 3:         System.out.println("The result is: " + faultyMethod());
 4:     }
 5: 
 6:     // This method should return an int, but it's missing a return statement.
 7:     public static int faultyMethod() {
 8:         int a = 5;
 9:         int b = 10;
10: 
11:         if (a < b) {
12:             System.out.println("a is less than b");
13:         }
14:         // No return statement here, but the method signature expects an int.
15:     }
16: }

================
File: test/main.py
================
 1: # main.py
 2: from fastapi import FastAPI, HTTPException, Request
 3: from fastapi.responses import JSONResponse
 4: from pydantic import BaseModel
 5: from typing import List, Optional
 6: import random
 7: import traceback
 8: import os
 9: import logging
10: from fastapi.logger import logger as fastapi_logger
11: 
12: fastapi_logger.setLevel(logging.ERROR)
13: 
14: app = FastAPI()
15: 
16: # Set this environment variable to True to display tracebacks
17: DISPLAY_TRACEBACK_ON_500 = os.environ.get("DISPLAY_TRACEBACK_ON_500", "False").lower() == "true"
18: 
19: class User(BaseModel):
20:     id: int
21:     name: str
22:     email: str
23: 
24: class Item(BaseModel):
25:     id: int
26:     name: str
27:     price: float
28: 
29: users = [
30:     User(id=1, name="Alice", email="alice@example.com"),
31:     User(id=2, name="Bob", email="bob@example.com"),
32: ]
33: 
34: items = [
35:     Item(id=1, name="Laptop", price=999.99),
36:     Item(id=2, name="Phone", price=499.99),
37: ]
38: 
39: @app.exception_handler(Exception)
40: async def debug_exception_handler(request: Request, exc: Exception):
41:     if DISPLAY_TRACEBACK_ON_500:
42:         return JSONResponse(
43:             status_code=500,
44:             content={
45:                 "message": "Internal Server Error",
46:                 "traceback": "".join(
47:                     traceback.format_exception(
48:                         etype=type(exc), value=exc, tb=exc.__traceback__
49:                     )
50:                 )
51:             }
52:         )
53:     else:
54:         return JSONResponse(
55:             status_code=500,
56:             content={"message": "Internal Server Error"}
57:         )
58: 
59: @app.get("/users", response_model=List[User])
60: async def get_users():
61:     # BUG: This endpoint will randomly fail
62:     if random.random() < 0.5:
63:         raise HTTPException(status_code=500, detail="Random server error")
64:     return users
65: 
66: @app.get("/items", response_model=List[Item])
67: async def get_items():
68:     # BUG: This endpoint will return items with incorrect types
69:     return [{"id": "not_an_int", "name": item.name, "price": str(item.price)} for item in items]
70: 
71: @app.post("/process")
72: async def process_data(data: dict):
73:     # BUG: This endpoint doesn't properly handle missing keys
74:     result = data['value1'] + data['value2']
75:     return {"result": result}
76: 
77: @app.get("/user/{user_id}")
78: async def get_user(user_id: int):
79:     # BUG: This endpoint doesn't properly handle non-existent users
80:     user = next((u for u in users if u.id == user_id), None)
81:     return user
82: 
83: @app.put("/item/{item_id}")
84: async def update_item(item_id: int, item: Item):
85:     # BUG: This endpoint updates the wrong item
86:     for i, existing_item in enumerate(items):
87:         if existing_item.id == item_id + 1:  # Intentional off-by-one error
88:             items[i] = item
89:             return {"message": "Item updated successfully"}
90:     raise HTTPException(status_code=404, detail="Item not found")
91: 
92: @app.get("/error")
93: async def trigger_error():
94:     # This endpoint always raises an exception to test the traceback functionality
95:     raise Exception("This is a test exception")
96: 
97: if __name__ == "__main__":
98:     import uvicorn
99:     uvicorn.run(app, host="0.0.0.0", port=8000)

================
File: test/test.c
================
1: #include <stdio.h>
2: 
3: int main() {
4:     int a = 10;
5:     int b = 0;
6:     int result = a / b;  // Division by zero leads to undefined behavior
7:     printf("Result: %d\n", result);
8:     return 0;
9: }

================
File: test/test.js
================
1: const num = 42;
2: 
3: function faultyFunction() {
4:   num = 10; // Attempt to reassign a constant variable
5:   console.log(num);
6: }
7: 
8: faultyFunction();

================
File: test/test.py
================
1: def hello():
2:     print("hello"
3: if __name__ == "__main__":    hello()

================
File: test/test.ts
================
1: const num = 42;
2: 
3: function faultyFunction() {
4:   num = 10; // Attempt to reassign a constant variable
5:   console.log(num);
6: }
7: 
8: faultyFunction();

================
File: utils/utils.py
================
  1: # [START utils.py]
  2: """
  3: This file creates a dependency graph that depicts the relationships between files. It will read the error stack, and attempt to parse it. Then, using the files mentioned, add everything.
  4: If the user does not provide a flag, the graph will only create itself from the error stack.
  5: If the user does provide "-g", the graph will contain all files from the repo, with respect to the .gitignore.
  6: If the user does provide "-r", the graph will contain all files from the error stack, alongside all files that are imported/included in the source file, and recursively call itself until all relationships are exhausted.
  7: 
  8: @usage: "splat <?-g> <?-r> <?entrypoint>"
  9: @note: if "splat" is not called with an entrypoint, the user will provide their own entrypoint when prompted
 10: @note: entrypoint will **always** be provided; assume there are 3 possibilities only
 11: """
 12: import os
 13: from typing import List, Set, Dict, Optional
 14: import ast
 15: import re
 16: import subprocess
 17: import signal
 18: from pathlib import Path
 19: from nltk.corpus import wordnet
 20: import nltk
 21: from repomixer.context_collector import ContextCollector
 22: 
 23: # Example run
 24: def main(error_info: str, flag: Optional[str] = None, project_root: str = './'):
 25:   project_root = os.getcwd()
 26:   error_files = [os.path.join(project_root, file) for file in parse_error_stack(error_info)]
 27:   print("************ERROR FILES*************")
 28:   print(error_files)
 29:   print("************ERROR FILES*************")
 30: 
 31:   if isinstance(flag, str):
 32:     print("FLAG CALL: " + flag)
 33: 
 34:   if flag == '-r':
 35:     graph = build_adjacency_list(error_files, project_root)
 36:     all_related_files = get_nth_related_files(error_files, graph)
 37:     return run_mock_repopack(list(all_related_files))
 38:   return run_mock_repopack(error_files)
 39: 
 40: def is_project_file(file_path: str, project_root: str) -> bool:
 41:   return os.path.commonpath([file_path, project_root]) == project_root
 42: 
 43: '''
 44: This function parses through a typical Python error trace stack and returns a list of all unique file paths found in the trace.
 45: @param error_info: str - a string that will be parsed for errors
 46: @note: The function uses a regular expression to extract file paths from the error message.
 47: @note: If a file path doesn't exist on the filesystem, it will not be included in the returned list.
 48: '''
 49: def parse_error_stack(error_info: str) -> List[str]:
 50:   """
 51:   Parse the error stack trace and return a list of all unique file paths involved.
 52: 
 53:   Args:
 54:   error_info (str): The full error stack trace as a string.
 55: 
 56:   Returns:
 57:   List[str]: A list of unique file paths involved in the error(s).
 58:   """
 59:   files = []
 60:   # This regex looks for file paths in various formats, including the command output
 61:   file_pattern = re.compile(r'(?:File "([^"]+)"|\b(\S+\.py)\b)')
 62: 
 63:   # Process each line of the error_info
 64:   for line in error_info.split('\n'):
 65:     matches = file_pattern.findall(line)
 66:     for match in matches:
 67:       # The regex returns a tuple for each match, we take the non-empty string
 68:       file_path = next((m for m in match if m), None)
 69:       if file_path:
 70:         file_path = file_path.strip()
 71:         # Remove any quotes around the file path
 72:         file_path = file_path.strip("'\"")
 73:         if os.path.exists(file_path):
 74:           files.append(file_path)
 75: 
 76:   return list(dict.fromkeys(files))
 77: 
 78: '''
 79: This function calls repopack to be used with a required parameter.
 80: @param paths: List[str] - A list of file paths to analyze using repopack.
 81: @returns: Dict - The JSON output from repopack parsed into a Python dictionary.
 82: '''
 83: def run_mock_repopack(paths: List[str], style: str = 'json') -> str:
 84:   """
 85:   A mock function that simulates what repopack might do.
 86:   It returns a string with file paths and their full content.
 87: 
 88:   Args:
 89:   paths (List[str]): List of file paths to be processed.
 90:   style (str): Output style (default is 'json', but not used in this mock version).
 91: 
 92:   Returns:
 93:   str: A string representation of the full file contents.
 94:   """
 95:   result = []
 96:   for path in paths:
 97:     if os.path.exists(path):  # Some paths are hallucinative / not real
 98:       with open(path, 'r') as f:
 99:         content = f.read()
100:       result.append(f"File: {path}\nContent:\n{content}\n")
101: 
102:   return "\n" + "="*50 + "\n".join(result) + "="*50 + "\n"
103: 
104: '''
105: This function runs through a source file and grabs all files linked by any Nth degree connection.
106: @param start_files: List[str] - The files to start with for finding related files.
107: @param graph: Dict[str, List[str]] - The adjacency list representing the relationships between files.
108: @returns: Set[str] - A set of all files related to the start_files to any Nth degree.
109: '''
110: def get_nth_related_files(start_files: List[str], graph: Dict[str, List[str]]) -> Set[str]:
111:   related_files = set(start_files)
112:   planned_visit = list(start_files)
113:   possible_files = set()
114: 
115:   while planned_visit:
116:     current = planned_visit.pop(0)
117:     possible_files.add(current)
118: 
119:     for neighbor in graph.get(current, []):
120:       if neighbor not in related_files:
121:         related_files.add(neighbor)
122:         planned_visit.append(neighbor)
123: 
124:   return possible_files
125: 
126: '''
127: Builds an adjacency list from a list of files.
128: @param files: List[str] - The list of Python files to analyze for import relationships.
129: @param project_root: str - The root directory of the project to ensure valid paths.
130: @returns: Dict[str, List[str]] - An adjacency list where each key is a file and its value is a list of imported files.
131: '''
132: def build_adjacency_list(files: List[str], project_root: str) -> Dict[str, List[str]]:
133:     adjacency_list = {}
134:     processed_files = set()
135: 
136:     def process_file(file: str):
137:         if file in processed_files or not is_project_file(file, project_root):
138:             return
139: 
140:         processed_files.add(file)
141:         imports = set()
142:         tree = None
143: 
144:         try:
145:             with open(file, 'r') as f:
146:                 content = f.read()
147:                 try:
148:                     tree = ast.parse(content)
149:                     for node in ast.walk(tree):
150:                         if isinstance(node, ast.Import):
151:                             imports.update(alias.name for alias in node.names)
152:                         elif isinstance(node, ast.ImportFrom) and node.module:
153:                             imports.add(node.module)
154:                 except SyntaxError:
155:                     pass
156:         except FileNotFoundError:
157:             return
158:         except Exception as e:
159:             return
160: 
161:         adjacency_list[file] = []
162:         file_dir = os.path.dirname(file)
163: 
164:         for imp in imports:
165:             module_paths = []
166:             if '.' in imp:
167:                 module_paths.append(os.path.join(project_root, *imp.split('.')) + '.py')
168:             else:
169:                 module_paths.extend([
170:                     os.path.join(file_dir, f"{imp}.py"),
171:                     os.path.join(project_root, f"{imp}.py")
172:                 ])
173: 
174:             for module_path in module_paths:
175:                 if os.path.exists(module_path):
176:                     adjacency_list[file].append(module_path)
177:                     # Recursively process the imported file
178:                     process_file(module_path)
179:                     break
180:             else:
181:               pass
182:                 #print(f"Warning: Imported module {imp} does not exist in the same directory or project root.")
183: 
184:         if tree is None and imports:
185:             adjacency_list[file].append(f"{file} (unresolved imports due to syntax errors)")
186: 
187:     # Start processing with the initial list of files
188:     for file in files:
189:         process_file(file)
190: 
191:     return adjacency_list
192: 
193: 
194: 
195: ################################################## NOT IMPLEMENTED BELOW #####################################################################
196: '''
197: This function uses a command and tries to check what type the file/directory is.
198: The idea is that we will have robust solutions specifically for different project types,
199: meaning that we need to determine what kind of project/file the user is working with.
200: '''
201: def detect_framework_or_language(command, directory='.'):
202:   # Dictionary to map commands, file presence, or file extensions to frameworks/languages
203:   indicators = {
204:     'go': {
205:       'commands': ['go run'],
206:       'files': ['go.mod'],
207:       'extensions': ['.go']
208:     },
209:     'rust': {
210:       'commands': ['cargo run'],
211:       'files': ['Cargo.toml'],
212:       'extensions': ['.rs']
213:     },
214:     'kotlin': {
215:       'commands': ['kotlinc', 'kotlin'],
216:       'files': [],
217:       'extensions': ['.kt']
218:     },
219:     'scala': {
220:       'commands': ['scala', 'sbt run'],
221:       'files': ['build.sbt'],
222:       'extensions': ['.scala']
223:     },
224:     'swift': {
225:       'commands': ['swift', 'swiftc'],
226:       'files': ['Package.swift'],
227:       'extensions': ['.swift']
228:     },
229:     'r': {
230:       'commands': ['Rscript'],
231:       'files': [],
232:       'extensions': ['.r', '.R']
233:     },
234:     'perl': {
235:       'commands': ['perl'],
236:       'files': [],
237:       'extensions': ['.pl', '.pm']
238:     },
239:     'haskell': {
240:       'commands': ['ghc', 'runghc'],
241:       'files': [],
242:       'extensions': ['.hs']
243:     },
244:     'lua': {
245:       'commands': ['lua'],
246:       'files': [],
247:       'extensions': ['.lua']
248:     },
249:     'julia': {
250:       'commands': ['julia'],
251:       'files': [],
252:       'extensions': ['.jl']
253:     },
254:     'c': {
255:       'commands': ['gcc'],
256:       'files': [],
257:       'extensions': ['.c', '.cpp']
258:     },
259:     'java': {
260:       'commands': ['javac', 'java'],
261:       'files': [],
262:       'extensions': ['.java']
263:     },
264:     'javascript': {
265:       'commands': ['node'],
266:       'files': [],
267:       'extensions': ['.js', '.jsx']
268:     },
269:     'typescript': {
270:       'commands': ['node'],
271:       'files': [],
272:       'extensions': ['.ts', '.tsx']
273:     },
274:     'python': {
275:       'commands': ['python', 'python3'],
276:       'files': [],
277:       'extensions': ['.py']
278:     },
279:     'nextjs': {
280:       'commands': ['next', 'npm run dev', 'yarn dev'],
281:       'files': ['next.config.js', 'pages'],
282:       'extensions': ['.jsx', '.tsx']
283:     },
284:     'fastapi': {
285:       'commands': ['uvicorn', 'python main.py'],
286:       'files': ['main.py'],
287:       'extensions': ['.py']
288:     },
289:     'react': {
290:       'commands': ['react-scripts start', 'npm start', 'yarn start'],
291:       'files': ['src/App.js', 'public/index.html'],
292:       'extensions': ['.jsx', '.tsx', '.js', '.ts']
293:     },
294:     'django': {
295:       'commands': ['python manage.py runserver', 'django-admin'],
296:       'files': ['manage.py', 'settings.py'],
297:       'extensions': ['.py']
298:     },
299:     'flask': {
300:       'commands': ['flask run', 'python app.py'],
301:       'files': ['app.py', 'wsgi.py'],
302:       'extensions': ['.py']
303:     },
304:     'vue': {
305:       'commands': ['vue-cli-service serve', 'npm run serve'],
306:       'files': ['src/main.js', 'public/index.html'],
307:       'extensions': ['.vue']
308:     },
309:     'angular': {
310:       'commands': ['ng serve', 'npm start'],
311:       'files': ['angular.json', 'src/main.ts'],
312:       'extensions': ['.ts']
313:     },
314:     'express': {
315:       'commands': ['node server.js', 'npm start'],
316:       'files': ['server.js', 'app.js'],
317:       'extensions': ['.js']
318:     },
319:     'spring-boot': {
320:       'commands': ['./mvnw spring-boot:run', 'java -jar'],
321:       'files': ['pom.xml', 'src/main/java'],
322:       'extensions': ['.java']
323:     },
324:     'ruby-on-rails': {
325:       'commands': ['rails server', 'rails s'],
326:       'files': ['config/routes.rb', 'app/controllers'],
327:       'extensions': ['.rb']
328:     },
329:     'laravel': {
330:       'commands': ['php artisan serve'],
331:       'files': ['artisan', 'app/Http/Kernel.php'],
332:       'extensions': ['.php']
333:     },
334:     'dotnet': {
335:       'commands': ['dotnet run', 'dotnet watch run'],
336:       'files': ['Program.cs', '.csproj'],
337:       'extensions': ['.cs']
338:     },
339:   }
340: 
341: def find_files_in_directory(directory: str, file_paths: List[str]) -> Dict[str, str]:
342:     """
343:     Find files in a directory given their full or partial paths.
344: 
345:     Args:
346:         directory (str): Root directory to search in.
347:         file_paths (list): List of file paths or names to find.
348: 
349:     Returns:
350:         dict: Dictionary mapping searched paths to found absolute paths.
351:     """
352:     root = Path(directory).resolve()
353:     found_files = {}
354: 
355:     for file_path in file_paths:
356:         # Convert to Path object
357:         search_path = Path(file_path)
358: 
359:         # Strategy 1: If it's just a filename
360:         if len(search_path.parts) == 1:
361:             matches = list(root.rglob(search_path.name))
362:             if matches:
363:                 found_files[file_path] = str(matches[0].resolve())
364:             continue  # Move to the next file_path
365: 
366:         # Strategy 2: If it's a partial path
367:         # Ensure the pattern is relative by removing any leading slashes
368:         pattern = search_path.as_posix().lstrip('/\\')
369: 
370:         # rglob expects a relative pattern, so ensure it's relative
371:         if pattern:
372:             matches = list(root.rglob(pattern))
373:             if matches:
374:                 found_files[file_path] = str(matches[0].resolve())
375:                 continue  # Move to the next file_path
376: 
377:         # Strategy 3: Try to match just the filename with directory pattern
378:         filename = search_path.name
379:         parent_dir = search_path.parent
380: 
381:         # Iterate through all matches of the filename
382:         for possible_match in root.rglob(filename):
383:             try:
384:                 # Get the relative path from root
385:                 relative_match = possible_match.relative_to(root)
386:                 # Check if the parent_dir is a suffix of the relative path
387:                 if Path(parent_dir).as_posix() in relative_match.as_posix():
388:                     found_files[file_path] = str(possible_match.resolve())
389:                     break  # Stop after finding the first relevant match
390:             except ValueError:
391:                 # possible_match is not under root
392:                 continue
393: 
394:     return found_files
395: 
396: nltk.download('wordnet')
397: def calculate_semantic_similarity(word1, word2):
398:     # Get synsets for both words
399:     synsets1 = wordnet.synsets(word1)
400:     synsets2 = wordnet.synsets(word2)
401: 
402:     if not synsets1 or not synsets2:
403:         return 0.0
404: 
405:     # Calculate maximum similarity between any pair of synsets
406:     max_sim = 0.0
407:     for syn1 in synsets1:
408:         for syn2 in synsets2:
409:             sim = 0
410:             if syn1:
411:                 sim = syn1.path_similarity(syn2)
412:             if sim and sim > max_sim:
413:                 max_sim = sim
414:     return max_sim
415: 
416: def error_repomix(entry_file: str, flag: str, query: Optional[str]):
417:     entry_file_path = find_files_in_directory(os.getcwd(), [entry_file])
418:     cmd = ['repomix', '--output-show-line-numbers', '-o shellypack.txt']
419:     match flag:
420:         case "-r":
421:             context_collector = ContextCollector("")
422:             related_files = context_collector.collect_context(query if query else "", entry_file_path)
423:             cmd.append(related_files)
424:         case "-g":
425:             cmd = cmd # repopack everything
426:         case _:
427:             cmd.append(entry_file_path)
428:     if os.path.exists('shellypack.txt'):
429:         os.remove('shellypack.txt') # delete the repopack if it exists
430:     subprocess.run(['repomix', '--output-show-line-numbers', '-o shellypack.txt']) # should add all related files to the array
431:     try:
432:         with open("shellypack.txt", 'r') as f:
433:             print(f.read())
434:         #os.remove("shellypack.txt")
435:     except FileNotFoundError as e:
436:         print(f'Repomix was unsuccessful...{e}')
437: 
438: 
439: ################################################## NOT IMPLEMENTED ABOVE #####################################################################
440: def extract_filename_with_extension(command):
441:   # Regular expression to match file names with extensions for the supported languages
442:   match = re.search(r'(\b\w+\.(go|rs|kt|scala|swift|r|pl|lua|jl|c|java|ts|py)\b)', command, re.IGNORECASE)
443:   if match:
444:     # Return the full file name with its extension
445:     return match.group(1)
446:   return None
447: 
448: 
449: def kill_process_on_port(port):
450:     try:
451:         # Find the PID of the process using the specified port
452:         result = subprocess.run(["lsof", "-t", f"-i:{port}"], capture_output=True, text=True)
453:         pid = result.stdout.strip()
454: 
455:         if pid:
456:             # Kill the process with the found PID
457:             os.kill(int(pid), signal.SIGKILL)
458:         else:
459:           return
460:     except Exception as e:
461:         print(f"Error: {e}")
462: 
463: # [END utils.py]

================
File: .env.example
================
1: API_KEY="your-api-key-here"

================
File: .gitignore
================
 1: .env
 2: */__pycache__/*
 3: ./test/test-nextjs-project/.next
 4: ./test/test-nextjs-project/node_modules
 5: ./test/test-react-app/node_modules
 6: ./splat.egg-info
 7: .DS_Store
 8: __pycache__/*
 9: ./zapenv
10: 
11: notes.txt

================
File: config.toml
================
1: [settings]
2: model="llama-3.1-8b-instant"

================
File: errortrace.py
================
 1: import subprocess
 2: import os
 3: import sys
 4: import shlex
 5: import threading
 6: import json
 7: import logging
 8: 
 9: logging.basicConfig(level=logging.ERROR)
10: 
11: def run_command(command):
12:     process = subprocess.Popen(
13:         shlex.split(command),
14:         stdout=subprocess.PIPE,
15:         stderr=subprocess.PIPE,
16:         text=True,
17:         bufsize=1,
18:         universal_newlines=True
19:     )
20: 
21:     def read_output(pipe, lines):
22:         for line in pipe:
23:             line = line.strip()
24:             lines.append(line)
25: 
26:     stdout, stderr = [], []
27: 
28:     stdout_thread = threading.Thread(target=read_output, args=(process.stdout, stdout))
29:     stderr_thread = threading.Thread(target=read_output, args=(process.stderr, stderr))
30: 
31:     stdout_thread.start()
32:     stderr_thread.start()
33: 
34:     stdout_thread.join()
35:     stderr_thread.join()
36: 
37:     return_code = process.wait()
38: 
39:     return '\n'.join(stdout), '\n'.join(stderr), return_code
40: 
41: def splat_find(command ):
42:     if command:
43:         print(f"Last command was: {command}")
44:         # Add specific logic to process this command
45:         stdout, stderr, returncode = run_command(command)
46:         json_file = {"stdout": stdout, "stderr": stderr, "returncode": returncode}
47:         return json.dumps(json_file)
48:     else:
49:         print("No last command found.")
50:         return None

================
File: humanloop.ipynb
================
  1: {
  2:  "cells": [
  3:   {
  4:    "cell_type": "markdown",
  5:    "metadata": {},
  6:    "source": [
  7:     "### LangGraph Agent - Customer Support multivoice Agent"
  8:    ]
  9:   },
 10:   {
 11:    "cell_type": "code",
 12:    "execution_count": null,
 13:    "metadata": {},
 14:    "outputs": [],
 15:    "source": [
 16:     "from dotenv import load_dotenv\n",
 17:     "\n",
 18:     "load_dotenv()"
 19:    ]
 20:   },
 21:   {
 22:    "cell_type": "code",
 23:    "execution_count": null,
 24:    "metadata": {},
 25:    "outputs": [],
 26:    "source": [
 27:     "from langchain_core.prompts import PromptTemplate\n",
 28:     "from langchain_openai import ChatOpenAI\n",
 29:     "\n",
 30:     "system = \"\"\"You are Andrea, a knowledgeable and friendly assistant in a telecommunications company. Your expertise lies in various mobile plans and upgrades. Your role is to help users understand their options and assist them with their queries about mobile plans and upgrades. Always respond in a helpful and professional manner.\n",
 31:     "Always speak to the user with his name.\n",
 32:     "\n",
 33:     "Username: {username}\n",
 34:     "\n",
 35:     "Remember, your goal is to make the user feel supported and informed. Always be courteous and clear in your responses.\n",
 36:     "\"\"\"\n",
 37:     "prompt_template = PromptTemplate.from_template(system)"
 38:    ]
 39:   },
 40:   {
 41:    "cell_type": "code",
 42:    "execution_count": null,
 43:    "metadata": {},
 44:    "outputs": [],
 45:    "source": [
 46:     "import requests\n",
 47:     "from langchain_core.tools import tool\n",
 48:     "from typing import Optional\n",
 49:     "import time\n",
 50:     "\n",
 51:     "API_URL = \"http://127.0.0.1:8000\"\n",
 52:     "ADMIN_USERNAME = \"admin1\"\n",
 53:     "ADMIN_PASSWORD = \"admin1password\"\n",
 54:     "\n",
 55:     "categories = [\"basic\", \"normal\", \"premium\"]\n",
 56:     "\n",
 57:     "def login():\n",
 58:     "    login_response = requests.post(f\"{API_URL}/token/\", data={\"username\": ADMIN_USERNAME, \"password\": ADMIN_PASSWORD})\n",
 59:     "    if login_response.status_code != 200:\n",
 60:     "        print(f\"Login failed: {login_response.json().get('detail')}\")\n",
 61:     "        return None, f\"Login failed: {login_response.json().get('detail')}\"\n",
 62:     "    access_token = login_response.json().get(\"access_token\")\n",
 63:     "    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n",
 64:     "    print(\"Login successful, headers obtained\")\n",
 65:     "    return headers, None\n",
 66:     "\n",
 67:     "def ask_admin(action: str, username: str, category: Optional[str] = None):\n",
 68:     "    try:\n",
 69:     "        headers, error = login()\n",
 70:     "        if error:\n",
 71:     "            return None, error\n",
 72:     "\n",
 73:     "        ask_data = {\"action\": action, \"username\": username}\n",
 74:     "        if category:\n",
 75:     "            ask_data[\"category\"] = category\n",
 76:     "\n",
 77:     "        print(f\"Requesting admin approval with data: {ask_data}\")\n",
 78:     "        response = requests.post(f\"{API_URL}/ask_admin/\", json=ask_data, headers=headers)\n",
 79:     "        if response.status_code != 200:\n",
 80:     "            print(f\"Failed to request admin approval: {response.json().get('detail')}\")\n",
 81:     "            return None, f\"Failed to request admin approval: {response.json().get('detail')}\"\n",
 82:     "\n",
 83:     "        print(\"Admin approval requested\")\n",
 84:     "        return \"Admin approval requested\", None\n",
 85:     "    except Exception as e:\n",
 86:     "        print(f\"Failed to execute ask_admin. Error: {repr(e)}\")\n",
 87:     "        return None, f\"Failed to execute. Error: {repr(e)}\"\n",
 88:     "\n",
 89:     "def wait_for_admin_approval(action: str, username: str, category: str = None):\n",
 90:     "    print(\"Waiting for admin approval...\")\n",
 91:     "    while True:\n",
 92:     "        response = requests.get(f\"{API_URL}/check_confirmation/{username}\")\n",
 93:     "        if response.status_code == 200:\n",
 94:     "            result = response.json()\n",
 95:     "            print(f\"Received admin approval response: {result}\")\n",
 96:     "            message = result.get(\"message\")\n",
 97:     "            # Exit loop if a final decision has been made\n",
 98:     "            if message in [\"Admin denied the request\", \"Contract created\", \"Contract will be cancelled in 3 months\"]:\n",
 99:     "                return result\n",
100:     "        time.sleep(2)  # Add a delay before retrying to avoid spamming the server\n",
101:     "\n",
102:     "\n",
103:     "@tool\n",
104:     "def create_contract_tool(username: str, category: str):\n",
105:     "    \"\"\"\n",
106:     "    Create a new contract for a user with a specific category.\n",
107:     "\n",
108:     "    Args:\n",
109:     "        username (str): Username of the user for whom the contract is being created.\n",
110:     "        category (str): Category of the contract. Must be one of \"basic\", \"normal\", or \"premium\".\n",
111:     "\n",
112:     "    Returns:\n",
113:     "        str: A string indicating the result of the admin approval process and contract creation.\n",
114:     "    \"\"\"\n",
115:     "    print(f\"Starting contract creation for user: {username}, category: {category}\")\n",
116:     "\n",
117:     "    # Step 0: Check if the user already has a contract\n",
118:     "    headers, error = login()\n",
119:     "    if error:\n",
120:     "        print(f\"Error during login: {error}\")\n",
121:     "        return error\n",
122:     "\n",
123:     "    print(f\"Fetching contract details for username: {username}\")\n",
124:     "    user_contract_response = requests.get(f\"{API_URL}/contracts/user/{username}\", headers=headers)\n",
125:     "    if user_contract_response.status_code == 200:\n",
126:     "        user_contract = user_contract_response.json()\n",
127:     "        print(f\"User contract details: {user_contract}\")\n",
128:     "        # Check if the user has a valid contract category\n",
129:     "        if user_contract.get('category') in categories:\n",
130:     "            return f\"User already has a contract: {user_contract}\"\n",
131:     "        else:\n",
132:     "            print(\"No valid contract found for the user.\")\n",
133:     "    elif user_contract_response.status_code == 404:\n",
134:     "        print(\"No contract found for the user.\")\n",
135:     "    else:\n",
136:     "        print(f\"Failed to fetch user contract details: {user_contract_response.json().get('detail')}\")\n",
137:     "        return f\"Failed to fetch user contract details: {user_contract_response.json().get('detail')}\"\n",
138:     "\n",
139:     "    # Step 1: Request admin approval\n",
140:     "    admin_request, error = ask_admin(\"create\", username, category)\n",
141:     "    if error:\n",
142:     "        print(f\"Error during admin approval request: {error}\")\n",
143:     "        return error\n",
144:     "\n",
145:     "    # Inform that admin approval is requested\n",
146:     "    if admin_request == \"Admin approval requested\":\n",
147:     "        # Wait for admin approval\n",
148:     "        approval_result = wait_for_admin_approval(\"create\", username, category)\n",
149:     "        print(\"APPROVAL RESULT: \", approval_result)\n",
150:     "\n",
151:     "        if approval_result.get(\"message\") == \"Admin denied the request\":\n",
152:     "            print(f\"Admin denied the request: {approval_result.get('message')}\")\n",
153:     "            return approval_result.get('message')\n",
154:     "        elif approval_result.get(\"message\") == \"Contract created\":\n",
155:     "            print(f\"Admin created the contract: {approval_result}\")\n",
156:     "            return f\"Contract successfully created: ID {approval_result['id']}, Category {approval_result['category']}, Contract Time {approval_result['contract_time']}, User ID {approval_result['user_id']}\"\n",
157:     "\n",
158:     "    return \"Unexpected flow reached\"\n",
159:     "\n",
160:     "tools = [create_contract_tool]"
161:    ]
162:   },
163:   {
164:    "cell_type": "code",
165:    "execution_count": null,
166:    "metadata": {},
167:    "outputs": [],
168:    "source": [
169:     "from langchain_core.messages.human import HumanMessage\n",
170:     "from langchain_core.messages.system import SystemMessage\n",
171:     "\n",
172:     "sys_msg = [SystemMessage(content=prompt_template.format(username=\"hans\"))]\n",
173:     "hu_msg = [HumanMessage(content=\"Please create a my premium contract for me\")]\n",
174:     "\n",
175:     "chat_history = []\n",
176:     "\n",
177:     "messages = sys_msg + chat_history + hu_msg\n",
178:     "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
179:     "model_with_tools = model.bind_tools(tools=tools)\n",
180:     "\n",
181:     "result = model_with_tools.invoke(messages)"
182:    ]
183:   },
184:   {
185:    "cell_type": "code",
186:    "execution_count": null,
187:    "metadata": {},
188:    "outputs": [],
189:    "source": [
190:     "messages.append(result)"
191:    ]
192:   },
193:   {
194:    "cell_type": "code",
195:    "execution_count": null,
196:    "metadata": {},
197:    "outputs": [],
198:    "source": [
199:     "result.tool_calls"
200:    ]
201:   },
202:   {
203:    "cell_type": "code",
204:    "execution_count": null,
205:    "metadata": {},
206:    "outputs": [],
207:    "source": [
208:     "from langchain_core.messages import ToolMessage\n",
209:     "\n",
210:     "for tool_call in result.tool_calls:\n",
211:     "    print(\"Use Tool:\", tool_call)\n",
212:     "    selected_tool = {tool.name.lower(): tool for tool in tools}[tool_call[\"name\"].lower()]\n",
213:     "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
214:     "    print(tool_output)\n",
215:     "    messages.append(ToolMessage(tool_output, tool_call_id=tool_call[\"id\"]))"
216:    ]
217:   },
218:   {
219:    "cell_type": "code",
220:    "execution_count": null,
221:    "metadata": {},
222:    "outputs": [],
223:    "source": [
224:     "messages"
225:    ]
226:   },
227:   {
228:    "cell_type": "code",
229:    "execution_count": null,
230:    "metadata": {},
231:    "outputs": [],
232:    "source": [
233:     "model_with_tools.invoke(messages)"
234:    ]
235:   }
236:  ],
237:  "metadata": {
238:   "kernelspec": {
239:    "display_name": ".venv",
240:    "language": "python",
241:    "name": "python3"
242:   },
243:   "language_info": {
244:    "codemirror_mode": {
245:     "name": "ipython",
246:     "version": 3
247:    },
248:    "file_extension": ".py",
249:    "mimetype": "text/x-python",
250:    "name": "python",
251:    "nbconvert_exporter": "python",
252:    "pygments_lexer": "ipython3",
253:    "version": "3.11.0"
254:   }
255:  },
256:  "nbformat": 4,
257:  "nbformat_minor": 2
258: }

================
File: module.py
================
 1: """
 2: This implementation is a pipeline that is a readable version of splat, where the pipeline can be easily seen here.
 3: @note: Splat only currently supports files that can be launched from root directory.
 4: @note: You are NOT to run this file.
 5: """
 6: # [START module.py]
 7: import os
 8: import json
 9: from typing import List
10: from relational import relational_error_parsing_function
11: from process.process import process
12: 
13: def main():
14:   """
15:   Running "splat <?-r> '<python3 filename.py>' will compile the Python file in a contained environment.
16: 
17:   If splat is called with no flag, then the error traces will only be scanned.
18:   If splat is called with a -r flag, then the error traces and its Nth degree connections will be scanned.
19: 
20:   If splat is not called with an entrypoint <python3 ?.py> then splat will prompt the user for an entrypoint.
21:   """
22: 
23:   '''CLI NEEDS TO PROMPT USER HERE + CLI NEEDS TO RETURN BACK FLAG & ENTRYPOINT'''
24: 
25:   # Handle relational adjacency list, and feed this to LLM
26:   entrypoint: List[str] = ['python3', 'foo.py'] # <-- will be filled in by CLI
27:   flag: str = "-r"
28:   traceback, error_info, repopack = relational_error_parsing_function(entrypoint, flag)
29: 
30:   # LLM now takes the data (all file context as type str, error message as type str)
31:   response: object = process(traceback, error_info, repopack)
32:   '''NOW WE NEED TO SPIT THIS BACK INTO THE CLI SEQUENTIALLY'''
33: 
34: # [END module.py]

================
File: README.md
================
 1: # splat
 2: splat is a tool that combines your compile/runtime errors and grabs context from every crevice to deliver a highly educated debug response. This is perfect for whenever you have an error that needs to be quickly fixed, understood, and prevented for later in the future.
 3: created at calhacks 11.0
 4: ## Features
 5: - **AI-Optimized**: We use an extremely fast inference model [Groq](https://groq.com/) in order to produce an instant debug error, with still the same amount of accuracy.
 6: - **Simple to Use**: <ins>splat</ins> can be used out-of-the-box and globally in any project without any configuration.
 7: - **Git Aware**: <ins>splat</ins> takes into consideration your .gitignore files so that we won't use any sensitive info.
 8: - **Highly Contextual**: You can use <ins>splat</ins> with a `-r` flag, grabbing all nodes to the Nth degree related to all error stack files in order to grab the most related content, delivering a highly accurate, optimized, and contextual debug response.
 9: 
10: ## Known Bugs
11: - <ins>splat</ins> will not conform to any formatting configurations when inserting code
12: - <ins>splat</ins> does not do well with running sub-module entrypoints that do not originate in the root directory
13:   
14: ## Quick Start
15: You can use <ins>splat</ins> out of the box:  
16: 
17: `splat squash <?-r> <!entrypoint>`.
18: 
19: Example:
20: Just like you would enter your app, do so with <ins>splat</ins>.  
21: 
22: `splat squash "python3 foo.py"`
23: 
24: `splat squash -r "python3 main.py"`
25: 
26: And that's it!

================
File: relational.py
================
 1: # [START relational.py]
 2: import os
 3: import json
 4: import subprocess
 5: from typing import Tuple
 6: from utils.utils import (
 7:   build_adjacency_list,
 8:   parse_error_stack,
 9:   run_mock_repopack,
10:   get_nth_related_files
11: )
12: 
13: def relational_error_parsing_function(entrypoint, flag: str = "") -> Tuple[str, str, str]:
14:   try:
15:     subprocess.run(entrypoint, capture_output=True, check=True, text=True)
16:     return "", "", ""  # Return empty strings if no error occurs
17:   except subprocess.CalledProcessError as error: # This will always run, on purpose.
18:     # Capture the error output to simulate the error stack
19:     traceback: str = error.stderr if error.stderr else str(error)
20:     error_information: str = str(error)
21:     collected_traceback_files = parse_error_stack(traceback)
22:     project_root = os.getcwd()
23:     #collected_traceback_files = [os.path.join(project_root, file) for file in parse_error_stack(error_information)]
24:     #print(collected_traceback_files)
25:     if flag == '-r':
26:       graph = build_adjacency_list(collected_traceback_files, project_root)
27:       all_related_files = get_nth_related_files(collected_traceback_files, graph)
28:       return traceback, error_information, run_mock_repopack(list(all_related_files))
29:     else:
30:       return traceback, error_information, run_mock_repopack(collected_traceback_files)
31: 
32: if __name__ == "__main__":
33:   relational_error_parsing_function(['python3', 'test.py'], '-r')
34: 
35: # [END relational.py]

================
File: requirements.txt
================
 1: click
 2: repopack
 3: setuptools
 4: virtualenv
 5: groq
 6: fastapi
 7: uvicorn
 8: prompt_toolkit
 9: requests
10: black
11: zmq
12: langgraph
13: langchain_openai
14: langchain_ollama
15: langchain_anthropic
16: langchain_groq
17: langchain
18: spacy
19: nltk

================
File: setup.py
================
 1: from setuptools import find_namespace_packages, setup, find_packages
 2: 
 3: setup(
 4:     name='shelly',
 5:     version='0.1',
 6:      py_modules=['shelly'],
 7:         install_requires=[
 8:         'Click',
 9:     ],
10:     packages=find_packages(),
11:     entry_points='''
12:         [console_scripts]
13:         shelly=shelly:cli
14:     ''',
15: )

================
File: setup.sh
================
 1: set -e
 2: echo "🚀 Running some setup commands..."
 3: 
 4: echo "Installing tmux!"
 5: brew install tmux
 6: 
 7: echo "Creating virtual environment..."
 8: python3 -m venv zapenv
 9: 
10: echo "Downloading dependencies..."
11: pip install -r requirements.txt
12: 
13: echo "Installing repomix..."
14: npm install -g repomix
15: 
16: echo "Setup complete!"

================
File: test.py
================
 1: import os
 2: from utils.utils import find_files_in_directory, get_nth_related_files, build_adjacency_list, error_repomix
 3: from repomixer.stack_trace_parser import StackTraceParser
 4: 
 5: cwd = os.getcwd()
 6: 
 7: #print(find_files_in_directory(cwd, ["yarn.lock"]))
 8: #adj_list = build_adjacency_list(["/Users/ryannguyen/projects/typescript/tutorportal/src/components/dashboard/dashboard/AttendancePanel.tsx"], "/projects/typescript/tutorportal")
 9: #print(get_nth_related_files(["/Users/ryannguyen/projects/typescript/tutorportal/src/components/dashboard/dashboard/AttendancePanel.tsx"], adj_list))
10: #print(repomix("test.py", ""))
11: 
12: parser = StackTraceParser("/projects/python/splat")
13: error_trace = """Traceback (most recent call last):
14:   File "/Users/ryannguyen/projects/python/splat/foo.py", line 6, in <module>
15:     from top.a import func_a
16:   File "/Users/ryannguyen/projects/python/splat/top/a.py", line 2, in <module>
17:     from a.y import func_y
18:   File "/Users/ryannguyen/projects/python/splat/a/y.py", line 2
19:     print("Noooope.)
20:           ^
21: SyntaxError: unterminated string literal (detected at line 2)"""
22: 
23: primary_files = parser.extract_files(error_trace)
24: print(f'primary files: {primary_files}')
25: 
26: all_files = parser.get_related_files(primary_files)
27: print(f'all files: {all_files}')
28: 
29: error_repomix("/projects/python/zap/foo.py", "", "")
